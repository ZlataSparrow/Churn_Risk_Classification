{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daee04f1",
   "metadata": {},
   "source": [
    "# Customer Churn Project — Part 3: Logistic Regression Classifier (Baseline Model)\n",
    "\n",
    "This notebook introduces the first predictive model for identifying high-risk users in our customer churn analysis pipeline. Building on earlier feature engineering, we train and evaluate a logistic regression model as an interpretable baseline for churn prediction.\n",
    "\n",
    "In this notebook, I:\n",
    "1. Assemble a behavioral feature matrix summarizing user engagement across sessions, songs, thumbs up/down, playlists, and activity duration.\n",
    "2. Train a logistic regression model to predict churn using PySpark’s MLlib.\n",
    "3. Evaluate performance using ROC-AUC and interpret key feature coefficients.\n",
    "4. Simulate a retention scenario: boosting user activity to test its impact on churn probability.\n",
    "5. Identify users most likely to benefit from engagement-based interventions.\n",
    "\n",
    "This model serves as a benchmark and provides early business insights into which behaviors most strongly influence user retention. More complex classifiers (e.g., Random Forest, XGBoost) are explored in the subsequent notebook: [04_Random_Forest_&_XGBoost.ipynb](04_Random_Forest_&_XGBoost.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4932dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65fe194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/16 13:30:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/openjdk-17.jdk/Contents/Home\"\n",
    "\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"CustomerChurn_EDA\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")  \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "#print(\"✅ Spark started:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d742051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(\"../data/churn_data_ready.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0d4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = (\n",
    "    data.groupBy(\"userId\")\n",
    "    .agg(\n",
    "        F.first(\"churn_flag\").alias(\"churn_flag\"),\n",
    "        F.countDistinct(\"sessionId\").alias(\"num_sessions\"),\n",
    "        F.sum(F.when(F.col(\"page\") == \"NextSong\", 1).otherwise(0)).alias(\"num_songs\"),\n",
    "        F.sum(F.when(F.col(\"page\") == \"Thumbs Up\", 1).otherwise(0)).alias(\"thumbs_up\"),\n",
    "        F.sum(F.when(F.col(\"page\") == \"Thumbs Down\", 1).otherwise(0)).alias(\"thumbs_down\"),\n",
    "        F.sum(F.when(F.col(\"page\") == \"Add to Playlist\", 1).otherwise(0)).alias(\"add_playlist\"),\n",
    "        ( (F.max(\"ts\") - F.min(\"ts\")) / (1000 * 60 * 60 * 24) ).alias(\"active_days\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062fd305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(userId='1567623', churn_flag=0, num_sessions=16, num_songs=1135, thumbs_up=65, thumbs_down=15, add_playlist=39, active_days=55.644050925925924),\n",
       " Row(userId='1396135', churn_flag=0, num_sessions=9, num_songs=974, thumbs_up=49, thumbs_down=9, add_playlist=21, active_days=52.782233796296296),\n",
       " Row(userId='1444744', churn_flag=1, num_sessions=21, num_songs=1406, thumbs_up=63, thumbs_down=15, add_playlist=53, active_days=57.14454861111111),\n",
       " Row(userId='1082354', churn_flag=0, num_sessions=13, num_songs=442, thumbs_up=19, thumbs_down=7, add_playlist=10, active_days=53.66190972222222),\n",
       " Row(userId='1633767', churn_flag=0, num_sessions=29, num_songs=2853, thumbs_up=138, thumbs_down=29, add_playlist=88, active_days=50.004502314814815),\n",
       " Row(userId='1187490', churn_flag=0, num_sessions=21, num_songs=1963, thumbs_up=95, thumbs_down=22, add_playlist=62, active_days=58.980358796296294),\n",
       " Row(userId='1180483', churn_flag=0, num_sessions=6, num_songs=168, thumbs_up=13, thumbs_down=1, add_playlist=4, active_days=50.52552083333333),\n",
       " Row(userId='1255222', churn_flag=0, num_sessions=109, num_songs=7970, thumbs_up=392, thumbs_down=88, add_playlist=225, active_days=60.817129629629626),\n",
       " Row(userId='1001958', churn_flag=0, num_sessions=44, num_songs=3519, thumbs_up=162, thumbs_down=34, add_playlist=101, active_days=58.38563657407408),\n",
       " Row(userId='1324309', churn_flag=0, num_sessions=22, num_songs=2619, thumbs_up=133, thumbs_down=39, add_playlist=74, active_days=54.59480324074074)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f001903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22261"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6afae",
   "metadata": {},
   "source": [
    "### I. Baseline Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fbe595",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"num_sessions\", \"num_songs\", \"thumbs_up\", \"thumbs_down\", \"add_playlist\", \"active_days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbcdd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (Baseline Logistic Regression): 0.855\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"churn_flag\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "train_df, test_df = user_features.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "lr_model = pipeline.fit(train_df)\n",
    "\n",
    "predictions = lr_model.transform(test_df)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"churn_flag\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"ROC-AUC (Baseline Logistic Regression): {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcafb1a",
   "metadata": {},
   "source": [
    "AUC-ROC (Area Under the Receiver Operating Characteristic Curve) shows how well the model can distinguish between churned and active users. The ROC-AUC = 0.855 means the model performs very well, it can correctly rank most users by their churn risk. \n",
    "\n",
    "\n",
    "So, for example, if we randomly select one churned user and one active user, there’s an ~85% chance the model will assign a higher churn probability to the churned user. This means features like num_sessions, thumbs_up, active_days, etc., are already quite informative — even without advanced models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35a78ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/1_vgy5852g7ctfxwwlkb1ks00000gn/T/ipykernel_25570/572184597.py:8: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap(\"coolwarm\")  # or \"seismic\", \"bwr\", etc.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAHgCAYAAABpW5/AAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcFRJREFUeJzt3QmczdX/x/HPWIax77SopGyhEBIlVFJaVFql0kJ7tNGqlTZCEr+KCv2U9qREKyVKoqhQpJQl+zaGuf/H+/z+39udO3O5M9+ZuXfufT0fj3HNne/93vM9d/vcz/mc800JBAIBAwAAAOJEsVg3AAAAAAhFgAoAAIC4QoAKAACAuEKACgAAgLhCgAoAAIC4QoAKAACAuEKACgAAgLhCgAoAAIC4QoAKAACAuEKACiSBESNGWP369ff688YbbxRoG37//XeLJ5dccok77qIq3vqzKD0Gf/zxh7vfJ554Ite3Xb9+vW3dujX4e//+/d2+0tPTfberY8eOOb42jzzySOvUqZPdd9997v6TRX72LYqeErFuAIDC06dPHzv00ENz/Fvz5s0L7H7vvfde+/nnn23SpEkFdh/JZNSoUfbKK6/Y559/HuumFElVqlSxxx57zOrVq5er23322Wd22223ub4vV66cu+7888+3Nm3aWMmSJfOlbZUrV7YBAwZkuW7Tpk02a9Ys++9//2sLFy50r6P8ur94lt99i6KFABVIIscee6y1bt260O935syZVq1atUK/30T15Zdf2p49e2LdjCKrTJkyduaZZ+b6dgsWLHDBYqhmzZq5n4JuW8+ePe3uu++21157zWbMmGGnnHKKJbr87lsULQzxAwBQBJx77rnu8rvvvot1U4ACR4AKIJvVq1e7YUZlXBs3bmxdu3a1CRMmZNvup59+sr59+1q7du3siCOOcNlZlRFoON+jGrI///zTvv/++2Cta6QaQNWa6XrVnoXWKernmWeecWUIug9lEHPTzmh4bXr99ddt6NChdtxxx7naP933b7/95v6uY1NG5/jjj7chQ4ZkyWJquwsvvNBli8844wxr2rSpdenSxQ0H76t/td1//vOfLPv7+uuvXXuUMTv77LOtSZMmdtVVV7k6xTlz5ti6devc31VfLLt377bnn3/eunXr5tqo7ZVlGz16tGVmZgb3q77VPvTYXXbZZXbUUUdZq1atXHs2bNiQpZ3bt2+3xx9/3NU/6ng6d+5sY8aMcfflCQQC9uKLL9ppp53m7rNt27Z21113ufblp2XLltmNN97oHn/dj7KM6ptwul+vb9UP1113nc2bNy9LnXVOzz/tX/2rIWUdq55Leky8vlO/Pf300+7/p556qnu8I9VJ/vPPP66sRc8TPYdOP/10e/XVV/Mlu5oTlXpcdNFF7rHUa0TH8eOPP2bbTq+bCy64wPVL+/btbeTIke6YQuuAvXp1lTOo/dqnSkpk165d7u8nnXSSe96ecMIJNnjw4Cw1ufLtt9+6/tHzSsev5+/kyZOzvQZuuukm9zrTvk4++WT3mtq5c2dwm5z6NjevHR3DI4884t6f9JiqZEB/Q9HAED+QRLZs2ZLjJIuyZctaqVKl3P/Xrl1r5513nvswUsBVtWpVV//2wAMPuEBNw4yydOlS92G333772eWXX27ly5e3xYsXu6BBQ6Eff/yxlS5d2tX6DRo0yP39+uuvz1Ot6w8//OCCiltuucUFu/qwibaduTV8+HCrUKGCC0b/+usve+GFF1y7d+zY4YIjfWhOnTrVBX4HHniga4Nn5cqVds0117jgRtd/8MEHNnDgQBewaB+yatUq9zc9FgoqtA8FtQqWdJzDhg3L0h59wOpD+JxzznGPk2ofn3zySXf899xzTzC40PG+9dZbbt/qDwUNb7/9tvvQT01NdY+RR8PUl156qQtUtW8FFAreFJB695+RkWE9evSwRYsWuQBDfT5//nx33zoGHZeoDQo+FIRpez0++pIwe/Zsd71qKv1SsKV96zjUZ9rntGnT3DH/+uuvdscdd7jttm3bZhdffLFrn7bXc/Odd95xj8nebNy40fVPiRIl7IorrnCPv4IbPSbqEwVSCm7Upx999JGrQ23YsGGO+1LfKtOpx0ePQ926de3TTz91/aS/KXjMK+1HQu9bj7meky1atLB+/fq59upLlu573Lhxwdebjkf9cMghh7hAX23Rc1vHnJPbb7/dlRWo/lOBpgJ13V4Bno5Pz7slS5bY+PHj7ZtvvrGJEye6x2f58uXuGA844AD35UDvK1OmTHFfWkS31RecK6+80tasWePuo0aNGi4rrNfU33//7d4zcpLb1879999vlSpVsquvvtq9fvUFTv9XP+bH8xIFLAAg4Q0fPjxQr169iD9jx44Nbtu/f/9A8+bNAytXrsyyj4cffthtu3jxYvf7wIEDA0cccURg9erVWbZ74okn3Hbffvtt8LoOHToEunfvHvxd+9Y2jz/+eJbb7ty5011/xx13BK/r0aOHu27WrFlZto22nZF4+w1vU5s2bQJbtmwJXn/DDTe46x988MHgddu2bXPHfv3112fb38iRI4PXZWRkBC644IJA48aNA+vWrXPX9evXz203d+7cLO1Rf+r6jz76yP0+e/Zs97tun1Pbjz322ODva9euDTRo0CBLG0XHofu+/PLLg9epb7Xf0aNHZ9tno0aNAtu3b3e/T5w40W03adKkLNvdfvvtgYYNGwbWrFkTmDNnTrbnj/zwww9um0GDBuXQ85Efg0jOP//8QJMmTQIrVqwIXrdnz55A7969szzW6vvQPpT09PRAt27d3PWvv/56js+/999/3/0+derU4O0yMzMDvXr1co9X+Oto6dKl2fpTz13RPvX7zJkzs+xLx9qyZUvXnkj0Omnfvn3gn3/+yfLz66+/uj5u2rRpoGvXru555T2+eg306dMny350vfal4/aceOKJbt+hz+0FCxYE6tevn+Ux8I5xyJAhWfb55ptvuuunTZuW5frp06e761966SX3+3/+8x/3u/Yd/hgMHjzY/f7999+7bZ577rlsr2n1k/orp77N7WtHfbVr167gdnr8c3pOIz4xxA8kEWWaxo4dm+1HQ7eiLIkyRBoC1HCisq3ej4bgQrM4GsLU0KKyHx5lKYoV+9/bijI5+UVZnqOPPjr4e27amVsaovZmaEudOnXcpYY1PbpPZWyVJQuljHFoplLtVqZSWd4vvvjCDUMqs6yMVOjxyLXXXusup0+fnuX6Y445Zp9t1gQ0ZUGVQQul/tCx5PRYaJg6lLJyymwpmyiffPKJu62yp6GUPVRWUhmoDz/80F2nTGzoY6DM5eGHH+724ZeG7JVdUwnBQQcdFLxezzNluUXPBe9SGcITTzwxuJ2yesqK7k2tWrXcpTJ4epz0eKWkpLiMmzLGuaFjPuyww9zzyKN9Pfroo26YP1LG0qOsvcoMQn9UqqHMvi6VsfT2oSF7ZXX1+g3tf7VfQ/jKPGtIXOUcWpZMWeDQ57ZXkpGT8OedRgN0W2VqQ+9Lr8GKFSsGH2uvL9VvyqzqOa/HQBl6L9Nds2ZN9/gp66rnkPf81EjLyy+/7PorXF5eO3ovCF0BoFGjRu4y/HWL+MQQP5BEvDrRSFSDqOEzfUjrgzHSMJvoQ0TbPvfcc+4DUMPbGt71asFC6x79UnmAPuTy0s7cCl9twAsGwq8vXrx4tmPUkGNaWlqW6xQwifpG7daHcU5LfVWvXt0NLWu7vbUnEvWPhlL1pUHDrApINm/e7P5Wu3btbNsrwA6/vXiPn9qh24UHVGqP16YVK1ZkC95D5cfyQF5/eF8UQmn4PHQbHXfLli0jbheJgqxevXq5L2saetYXEAVoCggVGO8rqAxvb05B3/777x/V7dW3qvv1vvCpnOTdd991tcUayg/tU6//vcAv0utAQ+mhz8XwvtEweU7tCKXnk4LhSK837zFQnylYfe+99+yrr75yQ+zqD/Wjapm9AFVt1tC8yg303NPjpufRWWedle01JHl57Wg5sVBe3+XnexMKDgEqgCAvOFFGzJsEEs7LmCqjoppQZdL0oaUPdGUo9KGpOlA/9x9OwWBe25lb4feVGzkFMt6Hof6mCUXiXea0bXhQ52Wk90YZM9VcqvZXGSZ92KtGT5eq8cvJvvbrZb72Ru1VjeGzzz5rBSVSX3n3L16fKQOcU5v3dRyigEl9qCysvvionlkZO9VzahJYTlm9SP0W7bY5UX9qApBHQZ3qOdXHylhqAl/48Ws0I6cAXhTQeV/WcuoHr/Z8X88PHZfa8dBDD0Vst/c8V/ZUWU31pYJf1Qvry5OCbE2qEk3QU622sp7qb9Usq8+VIVbtcniQWlCvHcQvAlQAWTIO+mBQwBP6ISn6cJw7d64dfPDB7ndleTSUq0kaocOGmqwQbRCo+wkV7czv3LSzMHkZ5NAgV1k9UXvUbmXnNIkrnLJcylB5Q6S58f7777tVEhSoaJKQxxuyz0uwrmBEAa8++EM/6DURTllzZRq1jQIQDWmH34eCO2XP/FJWWjQZKpx3nddn6mOvv0N5mcZI9JzRyhMaOlbgpB9NuNJscQ1Ba3F8TRKLhjKlOd2f+kmZUE24ijab6tFttBKBHmcNsSuQFvW/aIg9/HWgCW16PqnsxCuNyEvfhD4OaoO+9IQHgmqXl51VSYEeF31pVXZWZRjKfmrC1JtvvulKRBQoa9RFE6000VI/ei3rPeWll15y5TmavBeqoF47iF98vQAQpOyHatdU26YPuFCqgdNwnGbviwIffSCEBqcaUvaW8gnNhirACR1WU+Ci+1KwE0rDgvndzsKksoPQU8YqQFT2TX2kpW4UuGppHi0Tpfq8UF4WUlnhfQnvT69uNHwoW2cc0jBx6LJQ0VI79XgqqAqlZbOUDVPA4A3ZagmwUHpMlEHTsfuloWYtVaQgKPT0rjp+1YxKhw4dgjWHmlmu/vXoebivpceUxVNQqpnuHq2Y4J1pyvvC4QXqe8vqqi2//PJLtsdXM+qVUczLCSt0v1rNQQGaspNa0UI0dK4AVLWyoV/29HzQa0ABttqu0h4FmHpu6vkQGpyGHvPe6HmpIXYdRyg9Llpqznvtqq5UfRn62tYoi748KLOsY9EXHwXZoa8VBa1ejWhOoxj59dpB0UEGFUAWt956q1tKRh8yWqpGmRENv+mDSB8QWrdQ9H99KOlDUEvZKHOi4VAtqSTKQHkUzChwUKCgGlhl3DSRRWUCyqhoWFpBjWrXos26RdvOwqTA+cEHH3QBij6Q1T86Ll3nBfIqi1A7NXHHWypHQ5s6O5ACPi/o2xv1p7JSymQqo6VARVmtO++805U8KLus+j/1r4ZeQx+LaGlCjTJeenx1DMp2aSKWJkhpGSHVEepHQaGCVk3u0bqZevw1TKuaQGX+oqHMb6RgTz9aTkqlCt27d3d9puPXsLGCFR2vF9iojtRrn7fMlPpAGVCJNPSuCWNa31U1ntq/am+VBdTzVRlLBXhev4tqVRUM5fRYaRkjtU2Pr7LZ2peCQA1ja2muaMoNcqL9KBB8+OGHXX9piSgFfno+6TotQ6b6TQVyOiWqsopaYswrO9EyT8piapkmbauMox6naKnv1beqG/WyzQpw1UfK5HoT0fS80f3rMdDrUpl1japopEVD+mqzyoH0pcMLtvXc0vNH7dHrRl8+c5Ifrx0UHQSoALJ9EGotU2UitY6msoIakrzhhhvcsK6XRbrvvvtclklDucqoKVhRUKggQRMilN3UB5Lottpes3T1IakAVWsUKiOk2yuzpEBAM3i9mdn51c7CpOBax6hsl7KXmsmuhdBDJxHpQ1U1dk899ZQLABU86kNZwZGCsGjqF3V8ChK0D82yV82v7kd9obUgFaAqYNf/NfSvgErlB96QcDQUSCkDqn1qmFtfPjRUrOBIgYdHNZEKlhSA6NjVBwpAFJzmNKElJ+qrnGjyiwJUDa9rGx2PghhlC/Uc0v2FrjKgLwH6u2bMa3tlT/WcVJsVvEcKDnU771gVhKnURPetIEjPV4+e1wo+tY2Gu3MKiBTEKkBTv+jxVcZS/aDfw1dOyC0F3foCpqBMj4cCTT1nFIgri6pF9PVFRZlffbEIDfQUUHsL8yswVDv1WlWmM3z2e07Ud3oeadF+TdxS4K9ssF7jes15k+70GtQwvdqiLy7K5nproip4FwXRynoq864vpXqsVKag14meN5HqYvPjtYOiI0VrTcW6EQBQ1CmTp6ybggfEhmpJFeiEDxF7w9Aano40Cz2RqRxCGffwlRu8Lzsqh8nrsmxAQaEGFQCQEDT8rKHn8FNvKuOnoW6vFCDZKA+lbGr4clRaD1T1nNFOAAMKE0P8AICEoNOtauKNstla0kjD3ar9VI2iTjWr7GoyUkZZQ/Eqw9D/te6rMqo6cYCGxb3T8ALxhCF+AMgHDPHHB/W/ZverRle1qlofVJOVVK+ZzNLT010Nqeq1tS6q6pQ1OVHBqbdaARBPCFABAAAQV6hBBQAAQFwhQAUAAEBcYZIUCtx3333nZpGGnx4PAAAkj4yMDDcxTxP19oUMKgqcgtNYlDrrPjVJgjLr7OibyOibyOibva81quWtQk9BC54ze5OMfRPIRTxABhUFzsucNmnSpFDvV+eN1llSdMYZnbEI/6JvIqNvIqNvIvvtt9/cMk46o5FWDsD/8JyJLBn7ZuH/n3Y4GmRQAQAAEFcIUAEA8Ennqq9evbq7BOAfASoAAD5VrlzZWrdu7S4B+EeACgCAT5ocpRnKTJIC8gcBKgAAPq1du9Y+/PBDdwnAPwJUAAAAxBUCVAAAAMQVAlQAAADEFQJUAAAAxBUCVAAAfKpWrZqddNJJ7hKAfwSoAAD4VLx4cStVqpS7BOAfASoAAD5t2LDB5s6d6y4B+EeACgCAT7t27bLVq1e7SwD+EaACAAAgrhCgImGlpKRYWlqau0RW9E1k9E1k9A2AwlKi0O4JKECBPXssJWxygj5IGzVqFLM2xTP6JjL6JjL6JrLSpUvHuglAQiFARUJQcPpdz1tt60/LYt0UAEmoxBGH2clXn23ly5ePdVOAhECAioSh4HTzd4ti3QwASaiCmR3Xpo3t2LEj1k0BEgI1qAAA+JRRorj9+OOPtnPnzlg3BUgIBKgAAPi0s0yqTZ482TZu3BjrpgAJgQAVAAAAcYUAFQAAAHGFABUAAABxhQAVAACfimVmWq1ataxkyZKxbgqQEFhmCgAAn8puTbfevXuzzBSQT8igAgAAIK4QoAIA4NOWCmn20EMP2erVq2PdFCAhEKACAJAP9uzZY4FAINbNABICASoAAADiCgEqAAAA4goBKgAAAOIKy0wBAOBTma077ZprrrHSpUvHuilAQiCDCgCAT8UzA1ajRg0W6gfyCQHqPjAjEwCwLzvSSto777xjmzZtinVTgIRAgLoXI0eOtOeeey74+4gRI6x+/fq2e/duiwcrVqxw7XnjjTdi3RQASGq7S5aw7777jjNJAfmEADUCBaHDhw+3nTt3Bq/r3r27TZo0yUqUoHQXAACgoBBp5UKtWrXcDwAAAApOwmZQlfl88skn7eSTT7bGjRtb8+bN7fLLL7dFixYFt1m4cKFdeeWV1qJFC2vdurXdeOON9scff7i/HXHEEe7y6aefdsPo4UP8o0ePdtusX78+y/2+/vrr1qBBA1u5cqX7/e+//7ZbbrnF7f/II4+0Hj162Pz58/N0TB988IGdfvrp1rRpUzv77LPt559/zrbNTz/9ZNdff70dc8wxrn3HHXecPfjgg8Fhp8cee8z1R3id1Lhx46xJkya2ceNGS09Pt/vuu89OOOEEt+1JJ51kTz31VNyUNgAAgMSWsAHq7bffbpMnT7arr77aXnjhBRswYIAtWbLE+vbt6yY+KZC76KKLbOvWrTZ48GB7+OGH3d8VxCpAmzhxotvPueee64b1wylQ1GntPvzwwyzXv/vuuy4Yrl27tm3YsMEuuOACF5DeeeedNmTIECtVqpT17NnTfvjhh1wdz4wZM+zmm2+2evXqudrYU045xe64444s26xZs8YuvvhiF4zqmFQ/e9ppp9n48eNt7NixbptzzjnHMjIybMqUKVlu+9Zbb1mnTp2sUqVKri8+//xzu/XWW13fdevWzQXk+gEAZJeavtvatm1rZcuWjXVTgISQkEP8u3btsu3bt9tdd91lXbt2dde1atUqGIyuXr3ann32WatQoYIL3NLS0tw2Bx54oF177bUuy6psp2hI/6ijjsp2H/vvv7/bpwK9Cy+8MBggfv3113b//fcHs5Lr1q2z999/3w466CB3nbKSZ511lg0dOtSef/75qI/pmWeesUaNGrmssCgzKt7v8ssvv7jsrbKd5cuXd9e1adPGZs2aZXPmzHHHVrduXRdAv/322y5AFwXrixcvdplemTt3rh177LFZ+q5MmTJWpUoVyyt9KdBjUhBSUlKCjyEAxEKp9Aw77sQT3ShUQb3XFUXe6B2Tx7JLxr4JBALuMztpA9TU1NTg7HsFo7/99pstX77cPvnkk2AA+80331i7du2yBDYK7j7++GP3/2iGsxVoKgjWfdSsWdMFoloDr0uXLu7vs2fPdhlPBbOh+2vfvr0LXtUOtTWacoUff/zRDd2H6ty5c5YAVcejH2VIly5d6mb5K2hVGYIXsHpZYWV01S916tSxN9980wXi+vbvBbUTJkxw5QkKhNXeyy67zPxQmxQEFwQ9hgreASBWdhcv5j5nVD5FOVR26hvkLNn6JjWKuCdhA1T54osv7JFHHrFff/3VDbmodtQbelEEr+F3PxlBL0B84IEHXGCq0gAN73fs2DEYDOo+FCR69azh9HcFtvuiNzy1uXLlylmur169epbfMzMzXRmBgkt9g1fQqXpVlRWErueqAFrD+BrWv+GGG+y9995zQWuxYv+r+Ojfv7+7rdb0GzRokPtR8K6gVrW0eaHA/bDDDrOCEO23MQAoKDvKlrIXX3zRjahpNA4WzA4qADvkkEMY6QqTjH2zdOnSqLdNyAD1999/t+uuu846dOjg6iZVD6ogRoGbAldREKkAMZxqL5X1rFat2j7vRwGv6janTp3q7kt1paFZTt2HJmCp/jUn4QFnJKoLVfCocoFQ4e0fM2aMK1kYOHCgC55VwiAKPkNpuP7UU091k64UcGq/qk0N/Xaj2l39KDusPlFJhI5N5QLRfvsJpf7X/QJAItOXcd7rslMARr/kLJn6JiUXCaWEnCSlQFETna666ipX++l1iBecKtN49NFH28yZM7Osc6psq27z7bffWvHixaO6Lw3zL1iwwF5++WWrWrVqsDbUq93UMLq+HWmGvPczbdo0N3Ep2lPiKQParFkzdzu13eOVLHjU7kMPPdSt1+oFpwowNcwffkYsBa365jZq1Chr2bJlsEZW3+i08oFXH6sMr/anetXNmze7Ol4AAICClJABqobUtZi+JiIp46dATkPZn376aTAI04QhDZ0rINUMec3G1zbKniorqqBWGdB58+a5SUORTnmqyUTKtr7yyituxnzoIv6q29R+Lr30UlcG8NVXX9lDDz3kMp2hgXM0NINfwa4yw5999pmrYdUSWKE0nK+VCLR/TYp67bXX3Kx+b9JYKE380pC7tgvNnnr1nNq3hqv0d9Wo6v60dJXfsggAAICkDFAPPvhgN3lI2cNrrrnG7r33Xne9spwKCjVBSkGYspj6vV+/fm5YXIGtMoelS5d22+u2ysYqiP3rr79yvC9lWr0lp5RNDaXso5aoUjCqmf19+vRxs/y1xqgCzdxQNlaBp1YKUCCt4FM1tqF69+7tMp0vvfSSa7OO5cwzz3RD88oOh5cEqCxBZQoqBwilIFoZVgWovXr1cn2p2lqdWQsAkF1KIOCSGtGOvgHYu5RApNQgEt4ZZ5zhSge8ZbEKik6IICpvKEhftOpmm7/790QMAFBYKjRrZMfNedON0CXLhJdoaPROK7g0bNgwaeoso5WMfbMwF/FAQk6SKir03UCZ133RN/L8mqm+bds2N5FKmWFlVYcNG5Yv+wUAAMgvBKgxpNrOSDP8Q2mZJ53aND+ofEFlB1qnT6dA1TqoAAB/tpYv7Zb5U3mUN+kUQN4RoMaQakB1OtZ9yc819ZSN9VYzAADkj0BKim3ZsiWqUTEA+0aAGkNaBzXatVABAACSRULO4gcAAEDRRYAKAACAuMIQPwAAPqVtS3cnZdGpqQH4RwYVAACfSuzJdKe11qmpAfhHgAoAgE/ppUra9OnT3Ux+AP4RoAIA4NOuUiVs1qxZ7mQoAPwjQAUAAEBcIUAFAABAXCFABQAAQFwhQAUAwKcSGbutWbNmlpaWFuumAAmBdVABAPApbUeGnXzGGbZjx45YNwVICGRQAQDwaU+xFFuzZo1lZGTEuilAQiCDioRRrkHdWDcBQJLa3fgwGzVqlPXs2dMqVKgQ6+YARR4BKhJCYM8ea/bSE7FuBoAk9ddff9nnY8bEuhlAwmCIHwkhpXjxbNepFmzRokXUhOWAvomMvomMvols586dsW4CkFAIUJGwAoGA+yDVJbKibyKjbyKjbwAUFgJUAADyQbFifKQC+YVXEwAAPtWsWdNOPfVUdwnAPwJUAAAAxBUCVAAAfPrnn3/s888/d5cA/CNABQDAp927d9vmzZvdJQD/CFABAAAQVwhQAQAAEFcIUAEAABBXCFABAPCpYsWK1qpVK6tUqVKsmxJXUlJSLC0tzV0iK/pm70rs4+8AAGAfFGh0PvlkK5bDaZeTvV8aNWoU62bEpXjum0AgEPPAmQAVAACftm3bZvPnz7d6ZQOWZhmxbg6QZ8XSylnpw1tYrBGgAgDg05YtW2zatGlWq0MLK5WaGevmAEUeNagAAACIKwSoAAAAiCsEqAAAAIgrBKgAAPhUqlQpq1evnqWWYGoHkB8IUAEA8Kly5cp24YUXWuVyabFuCpAQCFABAPBpz549bqmpPZnM4AfyAwEqAAA+rV271p544glbt3lbrJsCJAQCVAAAAMQVAlQAAADEFQJUAAAAxBUCVAAAAMQVAlQAAHyqUaOG9e/f36pXLBfrpgAJgQAVAACfihUr5hbrL5aSEuumAAmBABUAAJ/Wr19v48ePtw1bt8e6KUBCIEAFAMCnXbt22bJly2zX7j2xbgqQEAhQAQAAEFcIUIuor7/+2urXr29ffvllrJsCAACQr0rk7+5QWI444gibNGmSHXbYYbFuCgAAQL4iQC2iypUrZ0cddVSsmwEAMLMKFSpYly5drHzKJrM9O2LdHKDIi6sh/o4dO9qIESNsyJAh1q5dO2vSpIlddNFFtmDBAvd3/U3D2rt37w7eRv/Xdfqb/PHHH+73999/366//noXxB177LE2cuRI27p1q919993WokULd92jjz5qgUAgV21cuXKl9e7d24455hhr2rSpdevWzd55550s2/z99992yy23WOvWre3II4+0Hj162Pz587Nso6H58847z5o1a+bac8UVVwSPUzZu3Gj9+vUL9sOpp55q48aN2+sQ/w8//GBXXnmlu9/mzZu7dv7888/ZbjN79my76qqrXN9o23vvvde2b/935umiRYvskksusZYtW7ptLrzwQvviiy9y1U8AkEzKlCljrVq1sjKlUmPdFCAhxF0G9cUXX3RB3UMPPWTp6ekuiFSg+fHHH+dqPwq6FNxefPHFNnnyZBs+fLi9++67LiB7+umn7cMPP7QXXnjBDZV37do1qn1mZma6oK9q1ao2ePBgt+ad9n3bbbfZfvvt5wK6DRs22AUXXGDFixe3O++802U6J06caD179nSXjRs3dkHutddea2eddZb17dvXBYcKoBWkfvLJJ+42CnDXrVvnjqNixYr20Ucf2aBBg6xSpUruduEUdCo4Pfroo+3hhx+2jIwMe/bZZ11bXnvttSylALpPXd+rVy8XOA8bNszKly/vjkNBvNqhYxk6dKgL4NVPffr0sQ8++MBq165teaH9hAbBhWHHjh1ZLvEv+iYy+iYy+iayzZs325IlS+yAXRlWKtaNAfKBXue5TeLti/aXEuVawSXi8VuoAquSJUsGO+iOO+6wH3/8MVf7UYZUGUg5/PDD7b333nPB3f333++uUwZUAeu8efOiDlC1zp2WEVGQesIJJ7jrFMhVr17dBaSiLKcCS2VwDzroIHedtlVQqYDv+eeft4ULF7rjUtBXq1Ytt02dOnXs9ddft23btrkAde7cue7vJ598svu7AmsNIVWuXDnHtj355JN24IEHuv17bWnbtq2ddNJJ9tRTT7mg3HP22WfbTTfd5P7fpk0b++qrr9wXAAWoOj4dpwJqBbuioFqPib4w5JUC5sWLF1ssLF++PCb3WxTQN5HRN5HRN9nt3LnTpk+fbj07tLDqJFGRAH777bcC+TKamppaNANUDZt7wanUrFnTXeY2+6ahc0+1atWC+/YogldmUt96o6XMab169VxWU0PeGn4//vjj3entQjOZ2mb//ffPUorQvn17F7xqrTwNm6elpdm5555rp5xyituPAmYFiB4FjgoqFdQp0NTtb7zxxhzbpb5R0KuA1gtORQFthw4dsmWfNfwfSkHy77//Hgzm1V/XXHONde7c2d33cccdZwMGDDA/9JgW9oQuvbD0QXrIIYe4/sa/6JvI6JvI6JvIVF4GJJI6derkewZ16dKlUW8bdwFq6dKls50+TnLbScpChvP7hqqgVsPdyiZOmzbNZWAVECqAu++++1xQqiH+FStWuNKBnOjv2k5nHBkzZoy98cYb9vLLL7vMsepZFezq24Uyovq7MrG6L1FG85577rEGDRpk2eeWLVtc/yiTG07Bpv6+t35QH6t8QdQOlSLoGFVWoPIABZcKVnWMCnrz2nfadyzoeGN13/GOvomMvomMvskuNLECJIK0AvgSGu3wflwGqNEcmBdMSWHXNSoIVJCoH9UbzZgxw0aNGmUDBw50AaVqOTXpKVLG0Rui17C56mKVZVUd6Ntvv20TJkxwwatqSRVgq0RBP6pZVW3qM88842pTp0yZkmWfuk/1zdq1a7Pdn65TaUNuHHzwwa7eVf2s0grVniowV3CqIBUAACBpZvFHmxXVLHmPakgLi+5Lta3ebHsNh2tYXcPzq1atctdpFqfqNjQEptn33o+yoMqa6lu2hvo19K7h/hIlSrjM6IMPPugyEtqPhoo0pD916lS3T01MUk2oZvJ79xNKt1PAq0Byz55/T7OnzOmnn37qAuZo6T51PApslVlV21V6ULdu3RzvGwDwvwyq5gGUDCmzApAkAaqCNlEWT8sraVLRAw88UGhDTY0aNXIlCArYNLyvZZuUNZ05c6YLHuWyyy5z2cxLL73UDc9rApJWJNB2mjSlv3kBoOo8FUDqWJRxVZG9alL1JqfaW83G1xD7nDlz3LD7W2+9FbyfcMqsqo5UM/CV1VWwqjZon1oFIVqqT1WQq7YpqFZN7eOPP+6yxVrjDwCQ8xwFvf9WKU/pA5AfShS1gl0tO6Uh9auvvtplMBXEadJSYVBwqqFurdOqZaY2bdpkBxxwgN18883ujUkUWOoMT6oh1YoBChAVmCqo1rJXohrS0aNHu6WlFOwqk6r1STUpShlY0d90P1rfVbPqa9So4W5/ww035Ng2TaoaO3as215lAfo2r8yshuq172ip/TpGzfxXGYNKKNTv6ueclrcCAADIbymB/J6iBYTRCgOicoHCpOBaqyA0bNiQCR1h6JvI6JvI6JvIVNr10ksv/f8yU//OkwCKmmJlKlqZpv8bsY5lPFCkMqgFRZOBQideRaIZ+7mZgQYAAIDcI0D9/+H00IXsI9G3Yy2YDwAAgIJDgGpm5513XvDMUHujWkwAAAAULALU/58Y5J2xCgAAALFVpJaZAgAgHumsfVplpSrLTAH5ggAVAACfdNKVKlWqWAkW6gfyBQEqAAA+bdy40d544w3buG1HrJsCJAQCVAAAfNJJWbTGY3rG7lg3BUgIBKgAAACIKwSoAAAAiCsEqAAAAIgrBKgAAPhUrlw5a9++vZUtnRrrpgAJgQAVAIB8CFB1RsJypUvFuilAQuBMUgAA+JSenm5//vmnVc3YbSVj3RggAZBBBQDApw0bNtiECRNYBxXIJ2RQAQDIJymlylixNM4mhaKrWFo5iwcEqAAA5JNSBzW0MvvtF+tmAL4EAgFLSUmxWGKIHwCAfDyjFP61Y8cOW7RokbtE0emblBgHp0KACgCAT8WLF7cyZcq4S2TNxCkA0yWyom/2jgAVAACfqlWrZh07dnSXAPwjQAUAAEBcIUAFAMCnNWvW2LRp09wlAP8IUAEA8El1hLt27aKeEMgnBKgAAACIKwSoAAAAiCsEqAAAAIgrBKgAAPhUuXJla9u2rbsE4B8BKgAAPqWmprrgVJcA/CNABQDApy1bttjixYtt69atsW5K3J0yMy0tLS5OnYmipUSsGwAAQFG3fft2W7Zsme3ZsyfWTYkrCk4bNWoU62bEBS1BRqAePQJUAADyyep1m23Hbj5akVVqyRJ2YC3qk3ODVxEAAPkkY/ce25meEetmAEUeNagAAACIKwSoAAD4VKZMGTv66KOtdOnSsW4KkBAIUAEA8KlChQp22mmnWdly5WPdFCAhUIMKAIBPGRkZtnHjRtu9OxDrpgAJgQwqAAA+/fPPPzZmzBjbtHFjrJsCJAQCVAAAAMQVAlQAAADEFQJUAAAAxBUCVAAAfNIpLFNTUzmVJZBPCFABAPCpZs2aNmDAAKtStVqsmwIkBAJUAAAAxBUCVAAAfFq3bp0988wztnHD+lg3BUgIBKgAAPi0e/duW7t2re3ZsyfWTQESAgEqAAAA4kpcB6iBAKeMAwAASDZxG6BOnz7dbr/9dvf/r7/+2urXr29ffvllzNozYsQI1wYN48TK8ccfb/3794/Z/QMAABSGEhannn/+eStRIm6bBwBAUKVKleyCCy6wQPGylhnrxgAJIG4zqAAAFBWlS5d2o2yppUrFuilAQojLAPWSSy6xefPm2Zw5c9wL3rN8+XK7+uqr7aijjrLWrVvbfffdZzt27Aj+vWPHjnbrrbdm2ddrr73m9vHHH38Eh+pPOukkmzFjhnXt2tWaNGliZ555pru/BQsW2HnnnWdNmzZ1f5s1a1a2tn3yySd2yimnuNudc8452baZMmWK29+RRx7p2njDDTfYb7/9lus+WLx4sV122WXWrFkzd1zab7j09HS3rInXHh3XmDFjLDPzf9/fr7/+ejvttNOy3Eb917BhQ9u0aVPwupEjR7q2avapSgh0v2+99ZZ16dLFGjdu7Pb/9ttv5/oYACBZbN261b744gvbsX17rJsCJIS4DFAVeCqobNSokU2aNMm98GXQoEEuEHv22WftwgsvtP/+97/29NNP53r/a9assYcffth69+5tw4YNs82bN9uNN95oN998sws6FbBpgla/fv1se9ibzV133WU9evRwgW6FChVcwDd//nz3t2+//dZuu+0269SpkwsUdRwKNLVNbiZ8rV692t2H2vX444+7tj366KNunT2P9tenTx/7z3/+49qsPjn11FPtqaeecm2U9u3b29KlS93xSkZGhs2dO9cFsLr06E1V9a3Fixd3v//www82atQot//Ro0fbfvvt5+qBtS8AQHb6nPr4449t+/ZtsW4KkBDissjzsMMOs7Jly7oaVGVLNUlKFLQpIynHHHOMmzT11Vdf5Xr/O3futHvuucc6dOjgflfg9eSTT9oDDzxg559/vrtOgakCw2XLlrmg2KOg08tKtmnTJhiMKpOpALVUqVIu8NWl1KpVyz777DPbtm2blStXLqr2jRs3zk3GUvBZtWpVd90hhxwSbJt8/vnn7vgfe+wxl7GVtm3buvtV0H3ppZfaCSec4M4Lre3OOusslyFWkFqvXj0XoJ544om2ceNGd33Pnj2D+96yZYv7YlC3bl33e506dVxf6c1Xj01eKKAOD/YLmpddD82y43/om8jom8jom8j03grsi147XsIqGV9PgUDAxSVFNkCNpEWLFll+r127djB7mVsaOvdUq/a/cydrWD604N0L1jzKMHbu3Dn4u4JBZR614oBomHzo0KGuPEDD7ccdd5wdffTR1rx581y1TYGuygy84FQUqOtczx6VPxQrVswNw4c644wzXICqvyvoVBZaQbwCVF1qvwq49XeZOXOm24+Ow1OxYsVgcOoF2X5fRHrzVjY5FlQagpzRN5HRN5HRNzknPoB9Uclf+Gdpsr2eUlNTEy9ALVOmTJbfFYXnda3UnLKZaWlpe72NgtbwlQUURGoo3gtwX3jhBfczfvx4txKBbnPxxRe7zG+03xpUHxpae+upXr16lm0USIY/0N42XpuU+VQdrsyePdsF0aorfemll9w2ysS2bNkyS3+o2D+UAljxalvzomTJknnOvuaV3gT0wlf2eV+PbbKhbyKjbyKjbyLz5jkAe6MRydAMarK9npbmolQwXwLUX375xT799FP7888/XdZOgeSSJUuyZOUKS3gQpaH1/KKATvv3AjZRXWiVKlWCv2vYXz+awKRhdA2Vq6b18MMPz5btjKRy5cr2zz//ZLt+w4YNwf8rOFWQumvXrixBqldvqn14daiq0/3xxx9dtvm6666zI444wgXLyqIqg6pa04Km+wv/glFY9MKP1X3HO/omMvomMvomu/Lly7sRq2izQ0hOOQWiyfR6SokyUZcvk6QeeeQRVwM5ZMgQe/XVV12AtHDhQjcx6JprrnEBVF54E3ZyQ1nAv//+O8t1mp2fXzRMHXqyAAW/CsyVlZTBgwe7CUv6dqTh/3bt2tn999/v/rZq1aqo70f1td9//32W2/z0009Zfm/VqpULlqdOnZrltu+8806WcggN56uEQZOe9MRQuYEmd2kmvzK9CoS9WlwAQN5otKx79+5WvkLFWDcFSAi+AtQJEya4oWJlTTWk7aWtVXepBYu1JJOGufNCQZRqNVQ36Q1X74sCLQWkmtGu4WzN1PdqLfODhqnvvvtuFwTq2K688kqXoldWUpQ5VaZSM/mVmdTw+Z133umCVU2mipYmOOnN7qqrrrIPP/zQ3n//fbdkVOg3c2WnFRgPHDjQnnvuORc4awa/JmupBrZBgwZuOwWl2vajjz5ydaze5C3dVrWumjClWl4AQN5pmT59VukSQIwDVC3zpJngAwYMyDKpRkPeCpw0pO1l9PKyFqrqPRWkRVt8rtnz+garzKCyt+vXr7eHHnrI8ouG1bXckiYhaYa/hvpffvnlYG2lhtO1GsCvv/7qak5vuukmN3N97NixrsYkWhqeV/B/4IEHunVJlaXWl4DQGk4FnloCSl8E1AZlrJVN1X1qZn8oL0OqrKvHy/qSPQUA/9auXesmyW7csD7WTQESQkogr7OM/n/4WBlCrUmq+khlEBWM6VI05K8spoarkbxU8iGhy3UVBn050MoBKmdIlvqeaNE3kdE3kdE3kWnETyOKp57R3cqW/98qMICndKmSdmjtfyc6J+vraWEu4gFfk6Q0DJ/TZB6PZqepcBz/o7VN90VZ2dBJWAAAAMnGV4Cq2sZXXnnFTQwKX5pIWVP97eSTT/bbxoRZgiSaOtRu3bq5yVYAAADJyleA2rdvXzc5R4vDa+F71UV6639qcpNqNlWrCbMaNWrY5MmT97mdtzwUAABAsirhN+h6/fXX3cQgnU1J5awzZsxwa3rpTEq33HKLHXDAAfnX2iJMM/ALuwYTAFA4dKa/u+66y1asWm/pu/ZdzgWgAANUZUl19qRBgwa5meaaKKUlNjSLPy/rmAIAUBRpBFErz+RmIXIAkRXzO8SvdTdFL0oFpjrVJsEpACCZaFnDcePG2eZNG2PdFCAhFPN7ZqX9998//1oDAEARpLMmrlixwn0uAohxgKozKeksRjprUzRLKAEAAAAFWoOqGfyqO7388svdsL7WRQ1fw1ND/1988YWfuwEAAEAS8RWgSuPGjfOnJQAAAIDfAFXngAcAINlpBPH000+30uXKxbopQELgnJoAAPikc6k3b97cSpdOi3VTgITgK4M6YMCAfW6jGlStkQoAQKLavn27LV682EqXr2aW4rt6Dkh6vl5Fb7755l7/XqlSJXe6UwAAEtnmzZvt3XfftVPP6G5ly1eKdXOA5A5QFyxYkO06nUlq3bp17oU6ceJEGzVqlJ+7AAAAQJIp5vf88uE/aWlpVrt2bbv22mvthBNOsMGDB+dfawEAAJDwCrRQ5sgjj6T+FACQNEqWKG6lS5WMdTMQZ1JLUpecWwXaY3PnzrVSpUoV5F0AABBzGkE86KCDrfb+1axq1aqxbg7iUCAQcBPHUQgB6pAhQyKek3jRokUuQD377LP93AUAAHGvcuXK1qJFc7fcFP61Y8cO++2336xOnTquBDCZEZwWYoA6ZsyYyDsuUcI6d+5st99+u5+7AACgSGTHdu7caZmZmbFuStz1i4JUXQKFFqDOmDEjx+uLFy/ulpgqXbq0n90DAFAkrFmzxqZOnWrVq1d32UIAMZzFryF8fSs64IADsvzUqlXLBafLli2z0aNH+2wiAAAAkkkxv2eSmj9/fsS/z54920aOHOnnLgAAAJBkcjXEv3LlSrvtttuCvyt7OmLECBs/fny2bVWHs3TpUjfcAQAAABRIgKoF+OvVq2czZ84MzkjT6d0yMjJyrEM9/PDD7YYbbsjNXQAAACDJ5XqS1AMPPBD8f4MGDezOO++0008/Pb/bBQBAkVGtWjXr1KmTuwQQ41n8P/30Uz40AQCAok2jhlrnU5cA4uBMUt6i/Nu3b8+y/tuePXts27Zt9uWXX9pDDz3k924AAIhbGzdutG+//db2228/FusHYh2g/vLLL9arVy/7559/Im6jb5MEqACARJaenm5//fWXuwQQB6c63bRpk1111VVuwpTWPL333nvdxKk33njDLVz8zjvv5EMzAQCJLjMzYMWKFc3TQXJiGiCOAtTvvvvOzjvvPOvXr587ldlzzz1nhxxyiB177LF20UUX2VlnnWUvvPCCDRw4MP9aDABISApOX/pgh61eX/ROF1qp1M5YNwFIKL4CVNWYaia/qDhcZ5FSPaoC1AoVKtjZZ59t7777bn61FQCQ4BSc/rG26AWomeU51zwQN2eSqlSpkm3dujXLOqlLliwJ/q5Tnq5evdpfCwEAiHMpJcpZx44drVy5crFuCpAQfAWoLVu2tMmTJwcnSdWvX9+++uorN9wvmtGoTCoAAIkspURZO+644whQgXgIUHv37m1//vmn+9a4YcMGO//88239+vV25pln2iWXXGJvvfWWdejQIb/aCgBAXArs2Wk///yz7dxJLSoQ8wBV9afKoJ5zzjlWuXJlO/jgg+2JJ55wa6AuXrzYTj31VLvtttvypaEAAMSrQMYm++9//+vWQwUQBwv1H3bYYW5pKc8pp5zifgAAAICYBKjegv2ffvqpG+7v2bOnO4uGJksdf/zx+bF7AAAAJBHfAeojjzxiL7/8sgUCAbdYv7KnW7ZssRtvvNHVnw4bNsxSU1Pzp7UAAABIeL5qUCdMmGAvvfSSy5qOHz/eBaly9NFH2wUXXGCffPKJPf/88/nVVgAA4lNKcatevbqVKJEvA5NA0vMVoKog/MQTT7QBAwZY3bp1g9dXqVLFnT2qS5cunOoUAJDwipWqZtdee61Vq1Yt1k0BEoKvAHX58uXWtm3biH9v06aNrVq1ys9dAAAAIMn4ClC1CL+3SH+kALZ8+fJ+7gIAgLiXmb7GBg0axNkTgXgIUDVL/5VXXrG//vor29++//5797e9ZVgBAEgIgYDt2rUrOBcDgD++qrn79u1rX375pZ1xxhnWrFkzN4tfk6U0MUqnPK1YsaKbzQ8AAAAUSga1Ro0a9vrrr7uJUt9995375jhjxgz79ttv7aSTTrJJkybZAQcc4OcuAAAAkGRylUF966233BJSBx54YPA6zVhU3Y3WQ92wYYM7zalm8RcvXrwg2gsAAIAEl6sMqpaTUqY0lGputBbqmjVrXGCqdeDiOTilPggAkN9SUqvY1VdfbVWrVo11U4DkC1BzCu62bdvmMqi//vqrxbvp06fb7bff7v7/9ddfW/369V0NbayMGDHCtWH37t0xawMAwL+UYiVtv/32s5IlS8a6KUBC8FWDWtSykpq89ffff8e6GQCABJOZsdmmTJlimzdvjnVTgISQLwEqAABJbc8O++abb2z79u2xbgmQEJImQL3kkkts3rx5NmfOHDesHnoyAdUNHXXUUda6dWu77777bMeOHcG/d+zY0W699dYs+3rttdfcPv7444/gUL1WLdAKBl27drUmTZrYmWee6e5vwYIFdt5551nTpk3d32bNmpWtbZ988omdcsop7nbnnHNOtm30rVz7O/LII10bb7jhBvvtt99ydfxvvPGGa/OKFSuyrWXbv3//4O/aZty4cXbHHXe4pcOOPfZYe+ihh2znzp25uj8AAICYrINalCjw7Nevn5vApf97Z8BS/awC1F69etns2bNt1KhRVq5cObvttttytX9NEnv44Yfd2rBly5a1Bx980K0Bm5qaar1797b999/fBg8e7NqggLRMmTLB2951111uW62O8OKLL7r2TJgwwQXNWrJLbenTp48LTtXuIUOGuG2mTZvm1p7NbyNHjnTB8FNPPWXLli1zlzo7igJxP2UghZ1Z8L5ohH7hwP/QN5HRN7HpG72XpaWlWVGXkZFBFjUEr6fIkrFvAoFA1HFLrgNUTYaaO3du8PctW7a4y59//tlKlMh5dy1btrRYO+yww1zgqDYq8NMkKenRo4fLSMoxxxzjJk3pJAO5pQzjPffcYx06dHC/L1261J588kl74IEH7Pzzz3fX6U1LgaiCPmVLPQqYTzvtNPf/Nm3aWKdOnWzMmDH2zDPPuAC1VKlSLsjVpdSqVcs+++wzN0FNwXR+02oMzz77rOur9u3bW7FixVwg/8svv1i9evXy/Ka9ePFiiwVlyZEz+iYy+qZw+0bBaaNGjayoW7t2bfBzEf/i9RRZsvVNampqwQSoClz0E+7RRx+NeJtYBSbRaNGiRZbfa9eubfPnz8/TvjQkHro+rCgT6alUqZK7DH3zUka3c+fOwd8VhGrYXSsOiLKmQ4cOdeUBKiM47rjj3Fq0zZs3t4Jy6qmnZvmyofYpQNUXk7wGqJrZqi8JhUnfSvXCP+SQQxIiM5Of6JvI6JvY9E1BjAYVquJlXJLjoIMOYqmpELyeIkvGvlm6dGnU2+YqQL3++ust0YQOtXtvknldlSCnbOa+nnQKWsMzz3pz82aCKsB94YUX3I93Glnd5uKLL3aZ34J4U69Zs2a29sjGjRvzvE+1M7yvC4seg1jdd7yjbyKjbyKjb7IrVrK8+zKvoCNZgo3c4DkTWTL1TUouYpakD1CjkZmZmeV3Da3nFwWi2r+G0T3r1q1zw+weDfvrJz093WUxdQpZ1Ykefvjh1qVLl1w9KXSmr1A51UqFB6Jqj5AVAICcBTJ32cqV661ChQoEqEA+SJpZ/JKXM1wpKxq+dqpm5+cX1WaGnixAwe+nn37qhvZFE6s0s19ZXQ3/t2vXzu6//373t1WrVuXqOESTnTxLlizJsVbq448/zvL7hx9+6ALctm3b5uEIASDxBXZtcCNd69evj3VTgISQNLP4Rd9steyTJkFt3bo1qtto0tPo0aNd3a0mV2kpKS1VlV9Um3n33Xe72f3ly5d3k6M0RHTddde5vytzqmWfNJP/rLPOctnWiRMnumBVk6mipYC3dOnS9thjj9nNN9/sAuHhw4cH62JDqY+0tJaWtvrpp5/c7H0tlaX6XAAAgIKWVBlUrYWqes+rrroq6nU9NXu+e/fu7pvxNddc474da13Q/FKxYkV3+tVhw4a5Gf4a6n/55ZeDE4o0i16rAWj1BNWc3nTTTW5YfuzYsa6wOjfBuQJNBbgKfhWc6v4aNmyYbVutbKCMrUo6tNyVlrjSSgMAAACFISVQVM5TikKhhfoVkGo91/yycOFCdxm6tFZhUCCvFSQUhCdLAXq06JvI6JvY9s3jE7fZH2uz1v0XBfuXX2s7V75sPXv2tDp16sS6OXGD11Nkydg3C3MRDyTVEH8i2r179z63UVY2dBIWACCfpRRzQQbvtUD+IEAtwnSq1WjqULt16+YmWwEACkaxUtXdXIFkOisQUJAIUIuwGjVq2OTJk/e5XeXKlaPep84IBgAAEEsEqEX8dGGFXdcJAMguM32dDR/+vBuxYsUTwD+KZQAA8CuwxzZs2BDVvAAA+0aACgAAgLhCgAoAAIC4QoAKAACAuEKACgCATyklK9nFF1+cq1VTAERGgAoAgE8pxUu5U1SXKlUq1k0BEgIBKgAAPgV2b7VPP/3Utm7dGuumAAmBABUAAJ8Cu7fZZ599RoAK5BMCVAAAAMQVAlQAAADEFQJUAAAAxBUCVAAA/Cpeypo0aWKlS5eOdUuAhFAi1g0AAMBTs0rRzJvUrFLFzj7lbNuxY0esmwIkBAJUAEBcyMwMWM9T0qwo2r17t61Zu87SSrMOKpAfiuZXVQBAwilWLMWKqpUrV9qoZ0baunXrYt0UICEQoAIAACCuEKACAAAgrhCgAgAAIK4QoAIAACCuEKACAOBTzZo1rWvXru4SgH8EqAAAAIgrBKgAAPi0fv16mzlzprsE4B8BKgAAPmVkZNjGjRvdJQD/CFABAAAQVwhQAQAAEFcIUAEAyCclS6bGuglAQiBABQDAp4oVK1q3bt2satUqsW4KkBBKxLoBAAAUdWlpada0adNYNwNIGGRQAQDwafv27TZnzhzbtm1brJsCJAQCVAAAfNq8ebNNnTrVXQLwjwAVAAAAcYUAFQAAAHGFABUAAABxhQAVAACfUlNTrW7duu4SgH8sMwUAgE9VqlSxHj16xLoZQMIggwoAgE+ZmZmWnp7uLgH4R4AKAIBPa9asscGDB9vq1atj3RQgIRCgAgAAIK4QoAIAACCuEKACAAAgrhCgAgAAIK6wzBQAAD5Vr17dbr31VitdunSsmwIkBAJUAAB8Kl68uKWlpcW6GUDCYIgfAACfNmzYYK+88oqtX78+1k0BEgIBKgAAPmmR/l9++cVdAvCPABUAAABxJaED1I4dO9qIESNsyJAh1q5dO2vSpIlddNFFtmDBAvd3/a1+/fq2e/fu4G30f12nv8kff/zhfn///fft+uuvt6OOOsqOPfZYGzlypG3dutXuvvtua9Gihbvu0UcftUAgkKs2rly50nr37m3HHHOMNW3a1Lp162bvvPNOlm2WL19uN954ozuGI4880i655BL75ptvgn/32vjhhx9a3759XXuaN2/u/r9u3bos+3r++eetU6dO7r4uuOAC+/jjj91tv/76a/d3ffu/77777IQTTrDGjRvbSSedZE899VSWPgIAAChICR2gyosvvmg//vijPfTQQ/bEE0/Y33//7QLN3AZc9957rx166KE2atQoa9OmjQ0fPtzOPfdcVxj/9NNP28knn2wvvPCCTZkyJep96pzNCk63b9/uTpE3evRodx+33XabzZ07122zdOlSO/vss10ge9ddd9mTTz5pxYoVs0svvdS++uqrLPtTsFy1alUXXN9yyy02Y8YMd9wetVN90KVLF3vmmWdcsK0gNtTDDz9sn3/+uZuNquNRwKx26QcAAKAwJPws/jJlytizzz5rJUuWdL/v2LHD7rjjDhe05oYypP369XP/P/zww+29996zSpUq2f333++uUwb03XfftXnz5lnXrl2j2qeK6ZctW+aCVGUspWXLlm65EgW+XlCptr/00ktWvnx5d5221X089thj9uabbwb317ZtWxekeu394YcfggGzguD//Oc/LoOs4FOUkdX1kyZNCu5DgbFu6x1Dq1atXB9WqVLF/FBmWfdVmPRYh17iX/RNZPRNZPRNZKmpqS5Rofdp9U9uR9MSFc+ZyJKxbwKBgKWkpES1bcIHqBrK9oJTqVmzprvMbbDUrFmz4P+rVasW3LdHHV6xYkXbvHlz1PtUtrNevXouO/vFF1+4gPH444+3/v37B7eZM2eOu84LTqVEiRJ22mmnueB1y5Ytwes1rB+qVq1abshemdr58+fbzp073RtoKAWioQGqssMTJkxwmebjjjvO2rdvb5dddpn5lZGRYYsXL7ZYUIkEckbfREbfREbfZKclpvT+KYsWLUqqoCMaPGciS7a+SU1NjWq7hA9QwxdN1vC45Pbbbbly5bJd53fNOwW1GkZXhnfatGkuA6vMqQJD1YHuv//+tmnTpmBAHMq7LjRADW+Pd6wKUL2lT8IzoQqSQyk4VmCrOthBgwa5nwYNGtidd95prVu3zvOx6kvCYYcdZoVJHxB64R9yyCGsTxiGvomMvomMvolMyQmNzKlMq06dOmRQ/x/PmciSsW+WLl0a9bYJH6DujZdmVgDnKexhaA3n33PPPe5nyZIlrm5Uda4DBw60MWPGuKxs+EQnWbt2rbtUmUE06+4p6BTtSyUKnvDb6pvN1Vdf7X5Wr17t6lEVQKtud9asWVF/88mpr1UqEAt64cfqvuMdfRMZfRMZfZOd3i8nT57s3jv322+/WDcn7vCciSyZ+iYlyuH9pJgkFU1WVMPZHtWQFhbdl+o9vVUFFDj26dPH1bOuWrUqWJOqIDE0U7pnzx5XW9qoUaOon9TKgqpMYPr06VmuV+Y29NucSgA0098rh+jevburW1V2QKsWAAAAFLSkzqCqvlJD2BpOv+qqq+yvv/5yy0cV1jcZBZgqQdCsfWUoa9SoYd9//73NnDnTrrvuOreNrleA2rNnT/fNvFSpUvbyyy+7Wf3KbOYmGL/yyitt2LBhVrZsWTdcr/pWnfnEKwfQtzi1SbWtqnNt2LCh/fnnnzZu3DgXNPudKAUAABCNpA5QVSektUs1pK7gTxlMLbOkSUuFQcGpalC1TquWmVK96QEHHGA333yzXXHFFW4btWnixIluG9WBepOztHyWsqu5odUCVBelSVG6X62pqhn9CtK9oFzLUimI1f7XrFnjSgi0bqq3ggEAAEBBSwlQyZ0UtO6rlsZS5jS0Pkoz9hWUaqH+ChUqFMh9L1y40F3qRAmFSfXEWjlAmeBkqe+JFn0TGX0TGX0TmU6YotIrrVutuQX4H54zkSVj3yzMRTyQ1BnUgqJJV6ETryLRjP3cFAz7oSF7rYOqzOg111xjlStXdueN1lmizjrrrAILTgEgGWhFFI1SAcgfBKgFQHWsquPcFy2+72fpptxSzapKBbRCgCY9aRkrnZGKN1UAABBPCFALwHnnnRc8M9S+amALU+3atW3o0KGFep8AkCzLTI0fP97NH2CZKcA/AtQCoOWZvDNWAQASn6ZzaAlAAPkjqddBBQAAQPwhQAUAAEBcIUAFAABAXKEGFQCAfFhmylvCD4B/BKgAAPhUsmRJ1pMG8hFD/AAA+KRTVb/zzju2cePGWDcFSAgEqAAA+LRjxw777rvv3CUA/whQAQAAEFcIUAEAABBXCFABAAAQVwhQAQDwqWzZsta2bVt3CcA/lpkCAMCn8uXL24knnhjrZgAJgwwqAAA+paen2/Lly90lAP8IUAEA8GnDhg324osv2tq162LdFCAhEKACAJBPMjJ2xboJQEIgQAUAAEBcIUAFAABAXCFABQDAp2LFilnp0qXdJQD/eCUBAOBT9erV3TJTugTgHwEqAAAA4goBKgAAPq1du9amT5/uLgH4R4AKAIBPmZmZtnPnTncJwD8CVAAAAMQVAlQAAADEFQJUAAAAxBUCVAAAfNiTGbD999/fevToYZUrV451c4CEQIAKAIAPxYul2Ctv/m1169a1UqVKxbo5QEIgQAUAwKe/Vq93y0xt2bIl1k0BEgIBKgAAPgUyd9qsWbNs27ZtsW4KkBAIUAEAABBXCFABAAAQVwhQAQAAEFcIUAEA8CklpZQ1a9bM0tLSYt0UICGUiHUDAAAo6lKKl7UzzjjDduzYEeumAAmBDCoAAD4FArttzZo1lpGREeumAAmBABUAAJ8CezbbqFGj7J9//ol1U4CEQIAKAACAuEKACgAAgLhCgAoAAIC4QoAKAIBvKVa8eHFLSUmJdUOAhMAyUwAA+FSsRGW78+67WWYKyCdkUAEAABBXCFABAPApc88mGz16NMtMAfmEABVRCwQCsW4CAMSnwB77+++/WagfyCcEqCF2795t9evXtxEjRux1u1tvvdU6duyY7/f/xx9/uPt/7bXX8nW/Oh7tV8cn/fv3t+OPPz7q269atcquvvpq+/PPP/O1XQAAADlhklQSuvbaa61nz55Rbz9r1iz77LPPCrRNAAAAHgLUJHTQQQfFugkAAADJN8S/c+dOe/LJJ+3kk0+2xo0bW/Pmze3yyy+3RYsWBbeZPXu2nXfeeXbkkUfaKaec4n4Pt3HjRrvjjjusVatW7kf7zEst5htvvOGG2efNm2fdunWzpk2b2umnn27vv//+Xm/3008/2fXXX2/HHHOMHXHEEXbcccfZgw8+GFzK5LHHHnPHt2nTpiy3GzdunDVp0sS1P1z4EL/65JJLLrGWLVvaUUcdZRdeeKF98cUXwXbffffd7v+dOnVytwUAZJVSrJyde+65VqlSpVg3BUgICZtBvf32223u3Ll2yy23uIzhihUrbNiwYda3b1/74IMPXFB25ZVXWuvWrW348OGu/lO1paEyMzPdNqq91P4qV65szz33nC1cuNBq1KiR5+H1Hj16uHZMnjzZ+vXrZ6VKlXLBX7g1a9bYxRdf7ILGwYMHu+001D527FirWrWq29c555xjzz//vE2ZMsUuuuii4G3feustt899vVlu3brVrrjiChecDh061AXfL7zwgvXp08f10wknnGC9e/d2s1OffvppF2Tnhfa7fft2K0xeEM+6hNnRN5HRN5HRN9lpYf60tDRLKZZqRxxR3yUFCvu9Lp7xnIksGfsmEAhEfTKLhAxQd+3a5d4g7rrrLuvatau7TtlPBWMK9FavXu0CLgWco0aNstTUVLeNgjkFjJ7PP//cBaPPPvusdejQwV2nTKafCVIKTpURFWVDlU0dOXJkjgHqL7/8Yg0aNLCnnnrKypcv765r06aNqwmdM2eOC1Dr1q3rssNvv/12MEBV1nXx4sUuON+XZcuW2fr1611N6tFHH+2uU0ZWx5yenm61a9d2P9KwYUM78MAD83TcmtmqNsXC8uXLY3K/RQF9Exl9Exl98y8Fp40aNbJA5k776quvXCKBFU+y4zkTWbL1Ter/x1xJGaDq4JXpFAWjv/32m3sCfPLJJ8EA9ttvv3XD3KEdddJJJ2WJ7L/55ht36rrQ4fCyZcu6wFJD9Xlx5plnBv+v+9J9KoO7bdu2bNu2a9fO/Si4W7p0qcsCK2hVQOkFrKJhpTvvvNMdZ506dezNN9+0WrVqWdu2bffZnsMPP9yqVatm11xzjXXu3NndRsc3YMAAy08lS5a0ww47zAqTvpXqcT/kkEPchwj+Rd9ERt9ERt9k531mBDK327Rp01yJVF6/yCcinjORJWPfLF26NOptEzJAFdVQPvLII/brr7+6oFJD07oUfbtVzWb48LeC1dDrtE2FChVckBqqevXqeW5XzZo1s/yuoXrZvHlztm1VYjBkyBCbMGGCywgr6FTtavg39C5dutjDDz/shvVvuOEGe++991zQWqzYvkuMy5QpYxMnTnQZ048++sgtcaVgUsHqfffd544/v97EdV+xoBd+rO473tE3kdE3kdE3ken9k77JjudMZMnUNylRDu8nbID6+++/23XXXeeG5TWUryFqdYoCPW/yjwLR8DN+7Nmzx7Zs2RL8XSUAClKVwdSbjieniUfR2rBhQ5Ygdd26dS6Q1H3p/6HGjBnj6k0HDhzoAkYvWFTwGUpP7FNPPdXVjKqmVvtRbWq0Dj74YBs0aJALiH/88Ue3H9Wh6v4UpAIAABSmhJzF/8MPP7j6yauuuspNkPIidi84VSCmWk7VmIYOret3bzF70TbaVplFj/arGtC8+vjjj4P/VxZUQ0ItWrSw0qVLZ9tWZQiHHnqode/ePRicqmRBw/zhNU4KWjVUoJpaTXiKdimpqVOnurratWvXukBZM/9vu+02V9uqBfolmkwsAABAfknIDKqWYypRooSbld6rVy9Xc6rlkj799NNg3YcmGE2fPt3N0lcgq7pOTUbS7UIDVNVk3nvvvS5resABB9iLL77osqre0HxuPf744649qhXVcLomKWmfOdFwvoJqZVI1k181qMoIe5PAQunvqvHU5ClNBIuWJlgpc6waVJ0tSoGw7nPJkiWub6RixYruUoG66nEVvAIA/pWSUtLq1avnSrAA+JeQqTENWWu9UmUbFXgpwJSXX37ZZVM1+UkB4ksvveQCUi35pMyjJhqVK1cuy760tJJWAtBEJm2nIDV8iD03NGSuwFQz+ZW11FC6N3s+nJZ30sx8tVNBtJaT0iQr3Va1tSoXCKWSBtXZqhwgWio3UBsUhN5zzz3ufhSgqqb1rLPOCgbq+lGfPvroo3k+dgBIVCnFy7sJUirXAuBfSoD1MAqFMriaGa8hfQXQBeGMM86wZs2a2f3332/xREt1icoHCpOyzFraSstjJUsBerTom8jom8jom8gGDV9sN15xkCu/Ck90JDOeM5ElY98szEU8kJBD/IUptGY1koKs4VQNrSZSqe5WWVWdjAAAULgCezbaE0+86taUJkAF/CNA9UFnn8ppgf1wWoxfJwooCJpcNWnSJBco6xSoKl0AAAAoyghQfdDpTnW60n1RTZIWbj777LPzvQ1ao9VbnQAAACAREKD6oIX9C7uuEgAAINEl5Cx+AAAAFF1kUAEA8CmleCXr379/VBNnAewbGVQAAHxKSSnmFunnzHtA/uCVBACAT5l7ttj48ePdWQkB+EeACgCAX4EMd+pqnYoagH8EqAAAAIgrBKgAAACIKwSoAAAAiCsEqAAA+JRSrIx16dLFKlSoEOumAAmBdVABAPAppVhpa9XqSNuxY0esmwIkBDKoAAD4FMhMtwULFhCgAvmEABUAAJ8CmdvszTfftE2bNsW6KUBCIEAFAMCnqpVLxboJQEIhQAUAwIc9mQE7o/N+sW4GkFAIUAEA8KF4sRTbuXNnrJsBJBQCVAAAfCpZsqRVqlTJXQLwjwAVAACfqlSpYu3atXOXAPwjQAUAAEBcIUAFAMCn1atX23vvvecuAfhHgAoAAIC4QoAKAACAuEKACgAAgLhCgAoAAIC4QoAKAIBPVatWtQ4dOrhLAP4RoAIA4FOJEiWsbNmy7hKAfwSoAAD4tHHjRvvuu+/cJQD/CFABAPApPT3d/vzzT3cJwD8CVAAAAMQVAlQAAADElZRAIBCIdSOQ2ObNm2d6mqWmphbq/eo+MzIyrGTJkpaSklKo9x3v6JvI6JvI6JvIdu/ebVu2bLHy5cszUSoEz5nIkrFvdu3a5Y61efPm+9yWVxEKXKxeeLrfwg6Kiwr6JjL6JjL6JjIFpZUrV451M+IOz5nIkrFvUlJSoo4JyKACAAAgrlCDCgAAgLhCgAoAAIC4QoAKAACAuEKACgAAgLhCgAoAAIC4QoAKAACAuEKACgAAgLhCgAoAAIC4QoAKAACAuEKACgAAgLhCgAoAAIC4QoAKAACAuEKAiiJr4sSJ1rlzZ2vatKl17drV3n333Xy73fTp0+3ss8+2Zs2a2YknnmjDhw+3Xbt2WVFRkH2zbNky69OnjzVv3txatWpl1113na1cudKKioLsm1Djxo2z+vXr24oVK6yoKMi+efPNN61bt27uNXXCCSfYgAEDbN26dRaPZs+ebeeff74dddRR1r59exs2bJjt3r3b923Wr19v/fv3tzZt2rh+0Ovo999/t6KkoPpm3rx5dvnll1vr1q3dzxVXXGGLFi2yoqSg+ibUggUL7IgjjrDXXnvNEl4AKILGjRsXaNCgQeCpp54KfP7554EBAwYE6tWrF5g2bZrv2+n6+vXrB/r27RuYOXNmYOzYsYEmTZoE7r333kCy982qVasCrVq1Cpx33nmBjz/+OPD+++8HTj755ECnTp0C27dvL4Sji9++CbVkyRL3nNE2y5cvDxQFBdk348ePd9c9+OCD7jX1+uuvB0444YRAx44dA1u3bg3Ek/nz5wcaN24cuPHGGwOfffZZYPTo0YEjjjgi8NBDD/m6ze7duwPdunVzx/3uu++6106XLl0C7du3D2zZsiVQFBRU3yxatMhtc/nllwdmzJgRmD59euCiiy5y1/3444+BZO6bUDt27Ah07tzZvZZeffXVQKIjQEWRoxdpy5Yts72I+/Tp497w/d7upptuCnTo0MF9oHieeOKJQKNGjQLp6emBZO4bBR/6gN22bVvwugULFgTatm0bmD17diCZ+8aza9euwFlnneUCj6ISoBZ037Rr1y7Qr1+/bB/O6p/XXnstEE969eoVOPPMMwOZmZnB6/QltWHDhoG///47z7d577333PEqGPOsXr3afZEZM2ZMoCgoqL7Rc0PvuaHvr3qPad26deC2224LJHPfhLr//vuD7yvJEKAyxI8i5/vvv7dNmza5IcVQXbp0ccPPkYabo73dzp07LS0tzYoXLx7cplKlSm7YZcuWLZasfaMvtNOmTXOlD2XKlAlu06RJE5s5c6Yblkvm543n6aeftu3bt9tVV11lRUVB9s2OHTvc3/W8CXXooYe6yzVr1li8UBnP119/bSeddJKlpKRkOZ49e/bYF198kefb6LJ27drWsGHD4DY1atSwFi1a2KeffmrxriD7plGjRtarVy9LTU0NbqP3mFq1asXV8yMWfePRe+zkyZNt4MCBliwIUFHk6INP6tSpk+X6Qw45JMvf83q7Hj162PLly+3555+3zZs32/z58+3FF1+0du3aWdWqVS1Z++aPP/5wAfoBBxxgDz74oAtIFZyqjm7VqlWW7M8b+e6779zzZvDgwe5LTlFRkH2jfrj77rutbdu22eq8pV69ehYvFFBnZGRkO56aNWta6dKlc+yHaG+jy/Bt5OCDD47Yv/GkIPtG9aZ63w2l2u0lS5bY4YcfbsncN6IvgXfeeafdcMMNdthhh1myKBHrBgChlKXcW/F32bJlbevWre7/5cqVy/Y38f4eLtrb6YP0yiuvtMcee8z9eN/whw4dasncNxs2bHD/HzJkiJsM8+STT7pJH7rs2bOnvf3228Htk61vRFnT22+/3S677DI3Aea3336zeBAPfRNOXwAfffRRa9CggXXo0MHihTdCEn483jFt27Ytz7fRdgceeGCO20Tqp3hSkH0TTln3O+64w2VUL730Ukv2vrn//vtt//33d4F8UUgG5BcCVMSV9PT0vQ5hKHt33nnn7XUfocMloTIzM6O63X333Wevv/66ywwee+yx9ueff7phW705KJMaOrydTH3jrWJQpUoV1x/Fiv1vAOaggw5ys1Dfeustu/jiiy0Z+0aUNVXm48Ybb7R4Eg99E+qXX35xr6USJUrYiBEjspTSxNq+jsfPbVQik9v+jScF2TehNGp17bXX2sKFC93qKTkF9cnUN++99559/PHHLgHgvecmCwJUxBV9c/z555/3us2ECRPcpb5hlipVap/ZHE/58uX3ebvVq1fbq6++6jKoffv2DW6jjOFpp53m/qYMWTL2jXdblTqEvlFqeRTdfvHixRYrse6bzz77zN544w233JL6RllL7wNI9WT6f6w+XGLdN6HUT/369bOKFSu6Ugh9uYknFSpUcJc5Zbx0nXe8ebmNLnPaRn2V037jTUH2jUdLbvXu3dtlCbXcUqdOnawoKKi+Wb16tT3wwAPus0hfJEPfV3Sp95Z4+oKX35IrHEdC8CZXhK8v6f1et27dPN9Ob4zKdGiNz1Cq+9FEqaVLl1qy9o0meIRmUkPpjVLZw2Ttm6lTp7p6su7du7s1CvVz1113BSc9qH4sWfvGoy9311xzjau5nDRpUo71mLGmgFkf+OFrkypQ0OTJnPoh2tvoeHNaE1e3i9S/ydI33vqeyuSrlEhrCGv96aKioPpm1qxZrv70kUceCb6vaFKV3HvvvcH/JyoCVBQ5qu/TMPuHH36Y5XoFCZqcEWlIKJrb6cNTbxrffPNNlm1+/fVX27hxowvSkrVvlIlr2bKlzZgxw72Bhi40rfpLzUZO1r65/vrr3Qzb0B9dJyNHjgz+Pxn7RqZMmeI+ULVA/fjx46169eoWj1TzqJNPaLWK0CFYHY9KEo455pg830YjD6q9Dc1ma4b6t99+6/4W7wqyb/T+qln8ei7py4ueV0VJQfVNhw4dsr2vjBo1ym2nL3ve/xMVQ/wocpSp0xI+qk/SC1kv8g8++MA++eQTNyzk0QQefTtV9lNDjdHcTvWVKsrXN3htoxpUZVVVc7nffvu5Wstk7RvR8Owll1zitlUZhDdJqnHjxnH/bb4g+0aBWHgQpxnIolnI8V5HV5B9owyQ6rq1Aoa2VQ1qKC0lpJ94ofpHvQdoxrQyegoodXwXXnihm6iiEQSd4Si03fu6jZdJHz16tOsDvY7Ud9pG7znarigoqL7RlxcNa2u1B2VQvQmZoudZUZi5XlB9U7ly5Sz3o9VUREP+OlNdQov1QqxAXmhhY511Q4s760wcXbt2DUyZMiXLNjpbjRY0Dl1APprbaRstlqwzduisHtr2rrvuCqxbty6Q7H0j3377baBHjx6Bpk2burNK3XnnnYFNmzYFioKC7puc9lMUFuovyL7R/3WbSD9DhgwJxBudzUgLqOv1r4XRhw0bFjxxx8qVK127hw8fHvVtPFp8XWcNat68eaBFixbuhAYrVqwIFCX53Td6X93b8+OCCy4IFBUF9bwJ5e0nGRbqT9E/sQ6SAQAAAA81qAAAAIgrBKgAAACIKwSoAAAAiCsEqAAAAIgrBKgAAACIKwSoAAAAiCsEqAAAAIgrBKgAYqJ///7uTCjemVEKk+63b9++ub6dznazbt264O8jRoxw+1q2bJnvNukMXdpX+E+TJk2sffv2duutt9qff/5pySI/+zYvdPrel19+2Z3hR2fIatq0qZ1++unubFDp6ekFfv86q1D37t3d46/TXup59/7777sztunMbRdccIG98cYbro8+//zzQnn+50ZGRob99ddfBXofSGyc6hRA0nnsscfcqQJz44cffnCnJnzooYfs+OOPd9cpWDjooIOsZs2a+dq28KBY52t/99133eXbb79tFSpUsERXEH0bLZ3OVY/1b7/9Zqeeeqp17dpVZ120r776yoYMGeJO5frCCy+4c8cXlAEDBtjSpUvdaTArVqxoxYsXtzvuuMNq1Khhd911l7usV6+ee740aNCgwJ//uaEvUldccYU7jWdROY0r4g8BKoCkc+aZZ+b6NjqH/OrVq7Ncp8Agt8FBXtp20UUXufORP/XUU/baa6+5D/9EVxB9Gw2dM/26666zNWvW2KRJk1y20qOAa9y4cTZo0CB7+OGH3U9B0fOtTZs2dvXVV7vf582b59qmzGlo0Fe7du1Cef7nhkZFFNwDfjDEDwBFwLnnnusuv/vuu1g3JaH997//dcGhspWhwannsssuc4HzlClTbNOmTQU6RF6uXLksv0vodUAiI0AFEPeUudSQ57HHHuuChi5duth//vMf27NnT7bh8EceecSOO+44O/LII13GS7V8jRo1cjWNkWrwtP+bbrrJ3U77P/nkk91Q7s6dO93fdVvdv1x11VXWsWPHiHWSql18/PHHrVOnTq5usXPnzjZmzBjbvXu3rz6INJy8YMECu/LKK6158+Z21FFHWY8ePdxQdE4lCsq8tmjRwmXm1E/KxobWAXs1jVOnTnXtVv3jvffe6/6mIe4XX3zRTjvtNHd927Zt3VBzaE2uqC/UR7oPHb+Gx/VYZWZmBrfZunWru22HDh1cf+vygQcesA0bNgS3yalvN2/e7EosVJOr26mPn3zySduxY0dwGx2LbqdjGzlypNu32nvGGWfYBx98sM9+fu+991xfa/tInnnmGZs1a5Ybeg897htvvNFat27t7k9ZSrUh3JYtW1zm1TsGlTKonV4A6j0GoppT/V/12j179nTXDRw40F339ddf51iDqueZ6mT1GlH/67mq56NeG3urQdU+lKnXc0jPJT2GP/74Y7Y6af3Mnj3bzj//fLd/PQ90PN5rRW0KbyuQFwzxA4hrq1atchNV9MGuD9ADDzzQZs6caU888YQLuoYNG+a2UwCkD1VlGDW5RPV5H3/8sftADQ2OwukDXQGehnT1waraPu1DH/J///23q9dTELF27Vo35KsgTx/gOVGQoQBx0aJFdvbZZ7sP8Pnz57sgSsehD+y8+vTTT91lw4YNg9cpENUxH3rooXb99de761Sr2qtXLxs6dKidcsop7jq1R/1Qvnx56927t+uP8ePHB4OicAoeFYDUqlXL1YHKPffcY5MnT3YThXSMqjOcMGGCC1Z0feXKlW3jxo12+eWXW4kSJVw/qVb2s88+c4+VAnd9CZCbb77ZvvnmG9ffGqJesmSJ25e+TOgyJwpONbStoWM9vgp81LcK/rUvBc+pqanB7UeNGuXqNtVWXY4dO9bd7zvvvOOeGzlREK6gTI9vyZIlIz4W4fWbuo3uR/ev56j6Ytq0aXb33Xfbr7/+6rKxoj7Qdqpx1VC9+lbHoGBc+1Cg2rJlS/ecu/32212wqP3tt99+rhb32Wefdc8rTZqqW7dujpPmVLOq572+YOgx1/3r2JUV1heFnLz11lsuCNaXl379+rl2vv76666/VdIQ+nxX/6s+V+0455xzbPr06fbSSy+5/lKb1f4+ffpkaSuQJwEAiIE77rgjUK9evcDKlSv3ul2/fv3cdnPnzs1y/cCBA931H330kfv9rbfecr+PHTs2uE1mZmagT58+7vrhw4cHr9fvN998s/v/999/735/7rnnsuy/f//+gR49erh9yOuvv+62++yzz4LbaJ+6bunSpe73iRMnut8nTZqUZV+33357oGHDhoE1a9ZEPE7dl277zz//ZPn5/fffA5MnTw60atUq0LZt28CmTZvc9nv27AmceOKJgW7dugV27doV3E96enqge/fublv9Xy699NLAUUcdFfjrr7+C261atcpdF/oYeMd4yy23ZGnbnDlzsvWt/PDDD+64Bg0a5H5///333XZTp07N8hj06tXLPY6iY9I2999/f5Z9DR061B3L5s2bc+zbJ5980v3+9ttvZ7ndmDFj3PXjxo1zv+tY9Puxxx4b3JfMnj3bXT9kyJCIj4HXtr59+wZy4/zzzw80adIksGLFiuB1enx69+7t9rd48WJ33YgRI1x/6TkX6sUXX3TbzZgxI8fnaGj79RzzhD8ndZnTMQ4bNsxd791v6L63bNkSaN68uXudhNL1HTp0cI9J+HN0ypQpWY6zU6dOgXbt2u21rUBuMcQPIG5pCF/ZIC3zc/TRR2f5m7I4ogyOfPTRR25oVhknT0pKissY7o0yU8WKFbOJEyfahx9+6LJHookwWmZI+4iWZnerRlCZo1C33Xaby9wps7YvGhoP/TnxxBNd5lXZLQ0ZezP4Fy9e7DJx+ruyy+vXr3c/Gj7Xdcr4KsOsOkkNB2toXhlRj7JyyobmJDzrpX4RDRd796Mf7ePwww93xy3e/pV9/uKLL9ykHvXf888/77LIov7Rj4avNRyszKgou6nfleXNiR5nZc/D26wyDu3Pex54VK4Rui+VeYj6JRI9DyQ35RgqcVDGXf3rZZu9fSmT6D03vX5UtlvHEdqPKkNQP3n9mFfe7dUnoZTV1uoPOQ23f/nll+45o4xraJv02KkMQZnd0MmBypRqRCH0OLXf8FIPwC+G+AHELdUkKmDUh3q46tWru2DNG+ZcsWKF7b///lmGeUVDofsKUDUEq2Fo1RDq9hqm1IfwWWedZWlpaVG3V23RkLWGuENVq1bN/URDw7Gi4XfVBSpwVmCoOr/QCTI6XlGJg1fmEE5lBToeDekfcsgh2f4eqW/C2+rdV2hgEsobDm/WrJkrL9AxqGxCXxgU7KrUQAGc+kXtefDBB10Zgep6VTqgemEF1QrsK1WqlON9qLZUX1TCvzBof+rz8OHuKlWqZNtO9lbuofvWdv/8849Fy7vfOnXqROxfbxt9oVCtpr54RHq8/ND96DURfuwK1COtiOA9tl4ZQqR2ect9aV/h5Q/ecwzITwSoAOKWagJDL8PpQ9H7sFRAl1MwWapUqX3ej2ZmazKPsnDK/KmuUpNgVKep+spog1RlfMMD5NzSRDCPMljKTimIU+ZP9YDhgZYyyQqoc6KlqbygJ6d2ReobL5Po0X1pW9UV7osCHdVZKmuovlQ/KguumkbViSrA1NqiynDOmDHDBeHK4j366KNubVFlUVUHHE7PgWieB5GOIVqqt/z+++9dBjHSY6nnhJ4rqveM1CavXeK1Tc8PBePKFufE7/q22n9uMv6hbdRkuJyCbAn9gpjXfgVyi2cagLilTJCycDmtqahJTRqa9IaVDz74YJehCp/Zv3z58r3eh4bH586d64IRTVzRRBVNPtIEHi2U7k1OioYmzyjTF55N0nD8Lbfc4i5zSxPENKNci/Rr4lPofUnp0qVdUBv6U7VqVRdgKbD2hp1z6gcvexbNcensSQp4w+9LGUG1QTQ0rL5TgKmgX0P7+l3DxyozWLhwoZtxryFxZcaVodZqCQpQNcFGQbhKIXKiYXE9D8IDQh2n+jy0fMEPreCgNmqyWU50/6+++qp7XiijrXaJJiOF867z2qZ+VMlFeB+qfEMTzPwu/O/tP3Q1BFG/aoJaTqs7eM8jrUgQ3i61R89l7/EFChMBKoC4pdnXJ5xwgs2ZM8fN1A7lZfO8JZ8UWChgDQ9wVEe6N1qmSRk/Ze48Cla9mkW1ITRztLeMmdqqmsrw4OaVV15x62aGD71GSxlUBX3KoCq7J1qiSNcpyxu6HqcCNmUxVa6gWkrdpzKsWmJJAaRHQUykICyclnPyllcKpRnoyuAqMyrKKiow1cx9T9myZYOz5tWXqmfUF4HnnnsuuI36VkszedtEaoOGsMPbrMdXSyipjjM/aIUAlUNoaabwZZZEX2D0GKhkQV+KVA6hrKhqavUFyaPATrW44rVNx6AvCto2lGbBa9mnnALI3NDzz3u+hXrzzTfd459ToKllonS9vkzoueNRwKznkMowIj0mkXjbM+wPPxjiBxBTygoqiAmnesZu3bq5zKOG3LVskbfMlIaNNTysD3wveFI2Tpkt1TYq6FS2T8tRKTsnkYY+VSOpAEOTeLw1NHUOcQV+CkA0zC5ecKmlphSE5jTBSEszKRjQh7qCN+1LmU8FzVoOKq+n7dTQryZKKRjU8SmYVhCtYVllxtRPyrSqPlBLBilTe+uttwYnZWkJIfWdFvtXcKi+UBCj7PHe+sajPtAXAN1GfaNTvapOU32ktnnLR2noXss+efen2lBlEbV0lLKERxxxhNtOGVUvsNRSSgqGtC+1V6UWOdEZlVQ2oH2rT9W3epx1vApuQyfH+aF+ffrpp10trR5PHZPaqLYq8Fa2XV8O7rvvvuBttJyUMu4KbtUOPVe0zJS+WGmpJ+/Ljibs6Rg0aU4ZZV2vIFiT37TP8Ml1uaVAWD+qSVa/q8+1vJReFwqo9ZoKpz7Xa0w1zlo2Sq8jBZg6YYFGKZThDq+p3hfveacvZepPPT9zuw+AZwyAmNLC6DlRNkcfbApIVfOn03wq+FOgoMDRW7zcC670oargSIGmFprXELI+oPW7Tl0ZqZ5Qt1M2VtlBzYJWAKrhTk0IUuDl1WlqYosWP9c2yuYqYAun+1A2cfjw4W7GtuouNcSuQNLvOckViCvI0Ie+2qvsltqorKrW/NSxK7urekGtoxl6OksFP9pOfaEMoIZuFYhoe01oiqZuVl8kVCOqgFArHGhCkYJ79ZFXo6ghb+/4FZRrZrcmsylo02PgUb2pbqPHSY+/ShHUv9qXts+JAmEFTdq3MrXqW02Ku+aaa1zg57f2N5RWJtBxKmjWfenLkGqcVaOp4FLPu9D703q3et4oMNRt9NzVFyT1U2jQqeeVttMxeHW5+tKi/ek4cjMhLyd6LWjfen6o//UcVB9pjdy9nR5X968VGZRF1ZqsqplV1ltftLwvaLmhyWEKzPVFSieE0MkLQlc4AKKRorWmotoSAOKYV8MXHqhoOFbZRWWIvNOFJhsFijmtIqAsoLJ36qO9LUwPAIWNGlQACUHDyBqKDZ/449X7KcuVrDSsr4xWKGWYNWSt5YcITgHEGzKoABKCau40rK2hSmVMNSQ8b948N1Sr4ezBgwdbstKwreoqVZagSTGaea9+0SlGVRqg6wAgnhCgAkgYmjSjWlJdaka/6t5UA6iZ5cm8fqNmU2uCkybLaKa5MqaaWKS6x/AzdAFAPCBABQAAQFxJ3pQCAAAA4hIBKgAAAOIKASoAAADiCgEqAAAA4goBKgAAAOIKASoAAADiCgEqAAAA4goBKgAAAOIKASoAAAAsnvwfipUSGrAnCDoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = lr_model.stages[-1].coefficients\n",
    "intercept = lr_model.stages[-1].intercept\n",
    "coef_df = pd.DataFrame({\"feature\": feature_cols, \"coefficient\": coefficients})\n",
    "\n",
    "sorted_coef_df = coef_df.sort_values(\"coefficient\", key=abs, ascending=True).reset_index(drop=True)\n",
    "\n",
    "norm = plt.Normalize(abs(sorted_coef_df['coefficient']).min(), abs(sorted_coef_df['coefficient']).max())\n",
    "cmap = cm.get_cmap(\"coolwarm\")  # or \"seismic\", \"bwr\", etc.\n",
    "colors = [cmap(norm(abs(c))) for c in sorted_coef_df['coefficient']]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.barh(sorted_coef_df['feature'], sorted_coef_df['coefficient'], color=colors)\n",
    "plt.xlabel(\"Logistic Regression Coefficient\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance Logistic Regression\")\n",
    "plt.axvline(0, color='gray', linestyle='--', linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b83fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf = predictions.select(\"userId\", \"churn_flag\", \"probability\").toPandas()\n",
    "pdf[\"prob_churn\"] = pdf[\"probability\"].apply(lambda x: float(x[1]))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(pdf[\"churn_flag\"], pdf[\"prob_churn\"])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0,1], [0,1], color=\"gray\", linestyle=\"--\")\n",
    "plt.title(\"ROC Curve — Logistic Regression\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0eee6",
   "metadata": {},
   "source": [
    "Together, the AUC score and the model coefficients suggest that the logistic regression model is highly effective at identifying churners based on a small set of behavioral features. The model doesn’t just rely on how much users engage, but rather on the quality of that engagement. For example, users who give more thumbs up or have more active days are less likely to churn, indicating that positive interaction and frequent activity are strong signals of retention. \n",
    "\n",
    "On the other hand, features like thumbs down are clear indicators of dissatisfaction and are positively associated with churn. Interestingly, even though features like the total number of songs played or sessions completed might suggest higher engagement, they don’t necessarily reduce churn and in some cases may slightly increase it — possibly capturing “last attempts” before a user leaves. Overall, these behavioral signals can be used to predict churn early and guide proactive interventions to improve user retention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ace6d",
   "metadata": {},
   "source": [
    "### II. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c555ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives (TN): 4586 — Correctly predicted 'Not Churn'\n",
      "False Positives (FP): 401 — Type I Error (Predicted 'Churn' but actually 'Not Churn')\n",
      "False Negatives (FN): 734 — Type II Error (Predicted 'Not Churn' but actually 'Churn')\n",
      "True Positives (TP): 752 — Correctly predicted 'Churn'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf[\"predicted\"] = (pdf[\"prob_churn\"] >= 0.5).astype(int)\n",
    "cm = confusion_matrix(pdf[\"churn_flag\"], pdf[\"predicted\"])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"True Negatives (TN): {tn} — Correctly predicted 'Not Churn'\")\n",
    "print(f\"False Positives (FP): {fp} — Type I Error (Predicted 'Churn' but actually 'Not Churn')\")\n",
    "print(f\"False Negatives (FN): {fn} — Type II Error (Predicted 'Not Churn' but actually 'Churn')\")\n",
    "print(f\"True Positives (TP): {tp} — Correctly predicted 'Churn'\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Churn\", \"Churn\"])\n",
    "plt.figure(figsize=(5, 4))\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Confusion Matrix — Logistic Regression\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc6591",
   "metadata": {},
   "source": [
    "Overall, the model correctly identifying a large number of users who stayed (True Negative = 4586) and users who churned (True Positive = 752). These cases are straightforward — the former require no action, and the latter represent users the model correctly flagged for potential retention strategies.\n",
    "\n",
    "However, two types of misclassification require closer attention:\n",
    "\n",
    "* False Positives (401 users) occur when the model predicts churn, but the user actually remains active. This is a Type I error. While it might lead to unnecessary retention offers or outreach, the cost is relatively minor since the user ultimately stays, and such actions could even strengthen their loyalty.\n",
    "\n",
    "* False Negatives (734 users) are more concerning. In these cases — Type II errors — the model predicts the user will stay, but they churn instead. These missed churners represent a direct loss in revenue and missed opportunities to intervene. From a business perspective, this is the most expensive error type, especially if these users have high customer lifetime value (CLV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b55140",
   "metadata": {},
   "source": [
    "### III. Churn Risk Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0fbbb8",
   "metadata": {},
   "source": [
    "Merging predicted data with the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d42e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>churn_flag</th>\n",
       "      <th>probability</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>predicted</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>add_playlist</th>\n",
       "      <th>active_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000214</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8917483617215857, 0.10825163827841433]</td>\n",
       "      <td>0.108252</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2005</td>\n",
       "      <td>101</td>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>58.426806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000353</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6496881041810953, 0.35031189581890465]</td>\n",
       "      <td>0.350312</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>239</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21.933322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000662</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9586365949189707, 0.041363405081029314]</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>899</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>52.006863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000908</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2755631428186788, 0.7244368571813212]</td>\n",
       "      <td>0.724437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001607</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9321081351054474, 0.06789186489455257]</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1929</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>54.774479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>1997746</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8801414431027844, 0.11985855689721558]</td>\n",
       "      <td>0.119859</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>655</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>49.912373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>1998434</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.43280675305817834, 0.5671932469418217]</td>\n",
       "      <td>0.567193</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9.842419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1999120</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9267482011289283, 0.0732517988710717]</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>43.872049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>1999892</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.477693499250673, 0.522306500749327]</td>\n",
       "      <td>0.522307</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>315</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>21.285961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>1999996</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9430037331357766, 0.05699626686422343]</td>\n",
       "      <td>0.056996</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>401</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>56.098032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6473 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  churn_flag                                 probability  \\\n",
       "0     1000214           0   [0.8917483617215857, 0.10825163827841433]   \n",
       "1     1000353           1   [0.6496881041810953, 0.35031189581890465]   \n",
       "2     1000662           0  [0.9586365949189707, 0.041363405081029314]   \n",
       "3     1000908           0    [0.2755631428186788, 0.7244368571813212]   \n",
       "4     1001607           0   [0.9321081351054474, 0.06789186489455257]   \n",
       "...       ...         ...                                         ...   \n",
       "6468  1997746           0   [0.8801414431027844, 0.11985855689721558]   \n",
       "6469  1998434           0   [0.43280675305817834, 0.5671932469418217]   \n",
       "6470  1999120           0    [0.9267482011289283, 0.0732517988710717]   \n",
       "6471  1999892           1      [0.477693499250673, 0.522306500749327]   \n",
       "6472  1999996           0   [0.9430037331357766, 0.05699626686422343]   \n",
       "\n",
       "      prob_churn  predicted  num_sessions  num_songs  thumbs_up  thumbs_down  \\\n",
       "0       0.108252          0            27       2005        101           25   \n",
       "1       0.350312          0             4        239         13            4   \n",
       "2       0.041363          0            15        899         87            7   \n",
       "3       0.724437          1             1         24          2            1   \n",
       "4       0.067892          0            20       1929        107           16   \n",
       "...          ...        ...           ...        ...        ...          ...   \n",
       "6468    0.119859          0            12        655         36           21   \n",
       "6469    0.567193          1             2        167          8            3   \n",
       "6470    0.073252          0             4         56          5            0   \n",
       "6471    0.522307          1            11        315         13           11   \n",
       "6472    0.056996          0            18        401         25            4   \n",
       "\n",
       "      add_playlist  active_days  \n",
       "0               64    58.426806  \n",
       "1                4    21.933322  \n",
       "2               31    52.006863  \n",
       "3                1     0.067361  \n",
       "4               51    54.774479  \n",
       "...            ...          ...  \n",
       "6468            25    49.912373  \n",
       "6469             5     9.842419  \n",
       "6470             5    43.872049  \n",
       "6471            11    21.285961  \n",
       "6472            14    56.098032  \n",
       "\n",
       "[6473 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_clean = user_features.drop(\"churn_flag\")  # in Spark\n",
    "user_features_pdf = user_features_clean.toPandas()\n",
    "pdf = pdf.merge(user_features_pdf, on=\"userId\", how=\"left\")\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7646a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 users at risk of churn (highest predicted probabilities):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ae92f_row0_col2 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ae92f_row1_col2 {\n",
       "  background-color: #c9181d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ae92f_row2_col2 {\n",
       "  background-color: #f0402f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ae92f_row3_col2 {\n",
       "  background-color: #fb7c5c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ae92f_row4_col2 {\n",
       "  background-color: #fca588;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ae92f_row5_col2 {\n",
       "  background-color: #fcc2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ae92f_row6_col2 {\n",
       "  background-color: #fdd4c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ae92f_row7_col2 {\n",
       "  background-color: #fed9c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ae92f_row8_col2 {\n",
       "  background-color: #fedecf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ae92f_row9_col2 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ae92f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ae92f_level0_col0\" class=\"col_heading level0 col0\" >userId</th>\n",
       "      <th id=\"T_ae92f_level0_col1\" class=\"col_heading level0 col1\" >churn_flag</th>\n",
       "      <th id=\"T_ae92f_level0_col2\" class=\"col_heading level0 col2\" >prob_churn</th>\n",
       "      <th id=\"T_ae92f_level0_col3\" class=\"col_heading level0 col3\" >num_sessions</th>\n",
       "      <th id=\"T_ae92f_level0_col4\" class=\"col_heading level0 col4\" >num_songs</th>\n",
       "      <th id=\"T_ae92f_level0_col5\" class=\"col_heading level0 col5\" >thumbs_up</th>\n",
       "      <th id=\"T_ae92f_level0_col6\" class=\"col_heading level0 col6\" >thumbs_down</th>\n",
       "      <th id=\"T_ae92f_level0_col7\" class=\"col_heading level0 col7\" >add_playlist</th>\n",
       "      <th id=\"T_ae92f_level0_col8\" class=\"col_heading level0 col8\" >active_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row0\" class=\"row_heading level0 row0\" >892</th>\n",
       "      <td id=\"T_ae92f_row0_col0\" class=\"data row0 col0\" >1561239</td>\n",
       "      <td id=\"T_ae92f_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_ae92f_row0_col2\" class=\"data row0 col2\" >0.995</td>\n",
       "      <td id=\"T_ae92f_row0_col3\" class=\"data row0 col3\" >93</td>\n",
       "      <td id=\"T_ae92f_row0_col4\" class=\"data row0 col4\" >5035</td>\n",
       "      <td id=\"T_ae92f_row0_col5\" class=\"data row0 col5\" >255</td>\n",
       "      <td id=\"T_ae92f_row0_col6\" class=\"data row0 col6\" >154</td>\n",
       "      <td id=\"T_ae92f_row0_col7\" class=\"data row0 col7\" >153</td>\n",
       "      <td id=\"T_ae92f_row0_col8\" class=\"data row0 col8\" >60.056574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row1\" class=\"row_heading level0 row1\" >1422</th>\n",
       "      <td id=\"T_ae92f_row1_col0\" class=\"data row1 col0\" >1884384</td>\n",
       "      <td id=\"T_ae92f_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row1_col2\" class=\"data row1 col2\" >0.974</td>\n",
       "      <td id=\"T_ae92f_row1_col3\" class=\"data row1 col3\" >92</td>\n",
       "      <td id=\"T_ae92f_row1_col4\" class=\"data row1 col4\" >6249</td>\n",
       "      <td id=\"T_ae92f_row1_col5\" class=\"data row1 col5\" >295</td>\n",
       "      <td id=\"T_ae92f_row1_col6\" class=\"data row1 col6\" >63</td>\n",
       "      <td id=\"T_ae92f_row1_col7\" class=\"data row1 col7\" >181</td>\n",
       "      <td id=\"T_ae92f_row1_col8\" class=\"data row1 col8\" >35.519988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row2\" class=\"row_heading level0 row2\" >5049</th>\n",
       "      <td id=\"T_ae92f_row2_col0\" class=\"data row2 col0\" >1116029</td>\n",
       "      <td id=\"T_ae92f_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row2_col2\" class=\"data row2 col2\" >0.962</td>\n",
       "      <td id=\"T_ae92f_row2_col3\" class=\"data row2 col3\" >123</td>\n",
       "      <td id=\"T_ae92f_row2_col4\" class=\"data row2 col4\" >7514</td>\n",
       "      <td id=\"T_ae92f_row2_col5\" class=\"data row2 col5\" >383</td>\n",
       "      <td id=\"T_ae92f_row2_col6\" class=\"data row2 col6\" >74</td>\n",
       "      <td id=\"T_ae92f_row2_col7\" class=\"data row2 col7\" >221</td>\n",
       "      <td id=\"T_ae92f_row2_col8\" class=\"data row2 col8\" >56.465799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row3\" class=\"row_heading level0 row3\" >4866</th>\n",
       "      <td id=\"T_ae92f_row3_col0\" class=\"data row3 col0\" >1988412</td>\n",
       "      <td id=\"T_ae92f_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_ae92f_row3_col2\" class=\"data row3 col2\" >0.947</td>\n",
       "      <td id=\"T_ae92f_row3_col3\" class=\"data row3 col3\" >84</td>\n",
       "      <td id=\"T_ae92f_row3_col4\" class=\"data row3 col4\" >3843</td>\n",
       "      <td id=\"T_ae92f_row3_col5\" class=\"data row3 col5\" >209</td>\n",
       "      <td id=\"T_ae92f_row3_col6\" class=\"data row3 col6\" >102</td>\n",
       "      <td id=\"T_ae92f_row3_col7\" class=\"data row3 col7\" >118</td>\n",
       "      <td id=\"T_ae92f_row3_col8\" class=\"data row3 col8\" >60.204132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row4\" class=\"row_heading level0 row4\" >5050</th>\n",
       "      <td id=\"T_ae92f_row4_col0\" class=\"data row4 col0\" >1117871</td>\n",
       "      <td id=\"T_ae92f_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row4_col2\" class=\"data row4 col2\" >0.937</td>\n",
       "      <td id=\"T_ae92f_row4_col3\" class=\"data row4 col3\" >40</td>\n",
       "      <td id=\"T_ae92f_row4_col4\" class=\"data row4 col4\" >2369</td>\n",
       "      <td id=\"T_ae92f_row4_col5\" class=\"data row4 col5\" >131</td>\n",
       "      <td id=\"T_ae92f_row4_col6\" class=\"data row4 col6\" >73</td>\n",
       "      <td id=\"T_ae92f_row4_col7\" class=\"data row4 col7\" >62</td>\n",
       "      <td id=\"T_ae92f_row4_col8\" class=\"data row4 col8\" >27.334502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row5\" class=\"row_heading level0 row5\" >1199</th>\n",
       "      <td id=\"T_ae92f_row5_col0\" class=\"data row5 col0\" >1748906</td>\n",
       "      <td id=\"T_ae92f_row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row5_col2\" class=\"data row5 col2\" >0.929</td>\n",
       "      <td id=\"T_ae92f_row5_col3\" class=\"data row5 col3\" >74</td>\n",
       "      <td id=\"T_ae92f_row5_col4\" class=\"data row5 col4\" >5127</td>\n",
       "      <td id=\"T_ae92f_row5_col5\" class=\"data row5 col5\" >245</td>\n",
       "      <td id=\"T_ae92f_row5_col6\" class=\"data row5 col6\" >60</td>\n",
       "      <td id=\"T_ae92f_row5_col7\" class=\"data row5 col7\" >150</td>\n",
       "      <td id=\"T_ae92f_row5_col8\" class=\"data row5 col8\" >38.479769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row6\" class=\"row_heading level0 row6\" >5056</th>\n",
       "      <td id=\"T_ae92f_row6_col0\" class=\"data row6 col0\" >1120634</td>\n",
       "      <td id=\"T_ae92f_row6_col1\" class=\"data row6 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row6_col2\" class=\"data row6 col2\" >0.924</td>\n",
       "      <td id=\"T_ae92f_row6_col3\" class=\"data row6 col3\" >43</td>\n",
       "      <td id=\"T_ae92f_row6_col4\" class=\"data row6 col4\" >2773</td>\n",
       "      <td id=\"T_ae92f_row6_col5\" class=\"data row6 col5\" >127</td>\n",
       "      <td id=\"T_ae92f_row6_col6\" class=\"data row6 col6\" >78</td>\n",
       "      <td id=\"T_ae92f_row6_col7\" class=\"data row6 col7\" >72</td>\n",
       "      <td id=\"T_ae92f_row6_col8\" class=\"data row6 col8\" >36.631725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row7\" class=\"row_heading level0 row7\" >1159</th>\n",
       "      <td id=\"T_ae92f_row7_col0\" class=\"data row7 col0\" >1730425</td>\n",
       "      <td id=\"T_ae92f_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row7_col2\" class=\"data row7 col2\" >0.923</td>\n",
       "      <td id=\"T_ae92f_row7_col3\" class=\"data row7 col3\" >82</td>\n",
       "      <td id=\"T_ae92f_row7_col4\" class=\"data row7 col4\" >7692</td>\n",
       "      <td id=\"T_ae92f_row7_col5\" class=\"data row7 col5\" >379</td>\n",
       "      <td id=\"T_ae92f_row7_col6\" class=\"data row7 col6\" >75</td>\n",
       "      <td id=\"T_ae92f_row7_col7\" class=\"data row7 col7\" >212</td>\n",
       "      <td id=\"T_ae92f_row7_col8\" class=\"data row7 col8\" >42.321910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row8\" class=\"row_heading level0 row8\" >805</th>\n",
       "      <td id=\"T_ae92f_row8_col0\" class=\"data row8 col0\" >1512450</td>\n",
       "      <td id=\"T_ae92f_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row8_col2\" class=\"data row8 col2\" >0.921</td>\n",
       "      <td id=\"T_ae92f_row8_col3\" class=\"data row8 col3\" >36</td>\n",
       "      <td id=\"T_ae92f_row8_col4\" class=\"data row8 col4\" >1958</td>\n",
       "      <td id=\"T_ae92f_row8_col5\" class=\"data row8 col5\" >88</td>\n",
       "      <td id=\"T_ae92f_row8_col6\" class=\"data row8 col6\" >66</td>\n",
       "      <td id=\"T_ae92f_row8_col7\" class=\"data row8 col7\" >62</td>\n",
       "      <td id=\"T_ae92f_row8_col8\" class=\"data row8 col8\" >29.439387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae92f_level0_row9\" class=\"row_heading level0 row9\" >2584</th>\n",
       "      <td id=\"T_ae92f_row9_col0\" class=\"data row9 col0\" >1600492</td>\n",
       "      <td id=\"T_ae92f_row9_col1\" class=\"data row9 col1\" >1</td>\n",
       "      <td id=\"T_ae92f_row9_col2\" class=\"data row9 col2\" >0.910</td>\n",
       "      <td id=\"T_ae92f_row9_col3\" class=\"data row9 col3\" >37</td>\n",
       "      <td id=\"T_ae92f_row9_col4\" class=\"data row9 col4\" >1879</td>\n",
       "      <td id=\"T_ae92f_row9_col5\" class=\"data row9 col5\" >83</td>\n",
       "      <td id=\"T_ae92f_row9_col6\" class=\"data row9 col6\" >58</td>\n",
       "      <td id=\"T_ae92f_row9_col7\" class=\"data row9 col7\" >65</td>\n",
       "      <td id=\"T_ae92f_row9_col8\" class=\"data row9 col8\" >28.524086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123216db0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# top 10 users most at risk of churning \n",
    "display_cols = [\"userId\", \"churn_flag\", \"prob_churn\", \"num_sessions\", \"num_songs\", \"thumbs_up\", \"thumbs_down\", \"add_playlist\", \"active_days\"]\n",
    "top_churn_risk = pdf.sort_values(\"prob_churn\", ascending=False).head(10)\n",
    "\n",
    "cols_in_pdf = [col for col in display_cols if col in top_churn_risk.columns]\n",
    "missing_cols = [col for col in display_cols if col not in top_churn_risk.columns]\n",
    "\n",
    "print(\"Top 10 users at risk of churn (highest predicted probabilities):\")\n",
    "if cols_in_pdf:\n",
    "    display(top_churn_risk[cols_in_pdf].style.format({\"prob_churn\": \"{:.3f}\"}).background_gradient(subset=[\"prob_churn\"], cmap=\"Reds\"))\n",
    "else:\n",
    "    print(top_churn_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef992a",
   "metadata": {},
   "source": [
    "The table above highlights the top 10 users with the highest predicted risk of churn, based on their behavioral patterns. All of these users have a predicted churn probability above 0.91, indicating a high level of confidence from the model. \n",
    "\n",
    "Interestingly, 8 out of 10 users in this list actually churned (churn_flag = 1), confirming that the model is correctly identifying high-risk individuals. Two users (user 892 and 5049) were predicted to have very high churn risk (0.995) but did not churn. This represents a False Positive, as described above, which—while not ideal—is less costly than missing an actual churner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4defe",
   "metadata": {},
   "source": [
    "### IV. Simple Retention Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645e867",
   "metadata": {},
   "source": [
    "In this section, I simulate how a small behavioral change (adding five more active days) affects churn probability for high-risk users. Even though I am using a baseline logistic regression model, it outputs probabilities, which allows us to run meaningful “what-if” scenarios.\n",
    "\n",
    "I focus on users with a predicted churn probability above 0.8 and simulate what happens if they become more engaged. After updating their active_days feature and re-running predictions, I compare the new probabilities to the original ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8a2917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5a18f_row0_col3, #T_5a18f_row1_col3 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row2_col3 {\n",
       "  background-color: #af0926;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row3_col3 {\n",
       "  background-color: #b71126;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row4_col3 {\n",
       "  background-color: #b91326;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row5_col3 {\n",
       "  background-color: #d02927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row6_col3 {\n",
       "  background-color: #d42d27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row7_col3, #T_5a18f_row8_col3 {\n",
       "  background-color: #d93429;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row9_col3 {\n",
       "  background-color: #dd3d2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row10_col3, #T_5a18f_row11_col3 {\n",
       "  background-color: #e0422f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row12_col3 {\n",
       "  background-color: #e24731;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row13_col3 {\n",
       "  background-color: #e75337;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row14_col3 {\n",
       "  background-color: #ef633f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row15_col3 {\n",
       "  background-color: #f26841;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row16_col3 {\n",
       "  background-color: #f36b42;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row17_col3 {\n",
       "  background-color: #f46d43;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row18_col3 {\n",
       "  background-color: #f57748;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row19_col3 {\n",
       "  background-color: #f67c4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row20_col3, #T_5a18f_row21_col3 {\n",
       "  background-color: #f7814c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row22_col3 {\n",
       "  background-color: #fcaa5f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row23_col3 {\n",
       "  background-color: #fdbb6c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row24_col3 {\n",
       "  background-color: #fdc776;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row25_col3 {\n",
       "  background-color: #fec877;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row26_col3 {\n",
       "  background-color: #feca79;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row27_col3 {\n",
       "  background-color: #fed27f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row28_col3 {\n",
       "  background-color: #fff7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row29_col3 {\n",
       "  background-color: #f1f9ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row30_col3 {\n",
       "  background-color: #eef8a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row31_col3 {\n",
       "  background-color: #ebf7a3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row32_col3 {\n",
       "  background-color: #dff293;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row33_col3 {\n",
       "  background-color: #cbe982;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row34_col3 {\n",
       "  background-color: #abdb6d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row35_col3 {\n",
       "  background-color: #73c264;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a18f_row36_col3 {\n",
       "  background-color: #39a758;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a18f_row37_col3 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5a18f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5a18f_level0_col0\" class=\"col_heading level0 col0\" >userId</th>\n",
       "      <th id=\"T_5a18f_level0_col1\" class=\"col_heading level0 col1\" >original_prob</th>\n",
       "      <th id=\"T_5a18f_level0_col2\" class=\"col_heading level0 col2\" >new_prob</th>\n",
       "      <th id=\"T_5a18f_level0_col3\" class=\"col_heading level0 col3\" >probability_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row0\" class=\"row_heading level0 row0\" >26</th>\n",
       "      <td id=\"T_5a18f_row0_col0\" class=\"data row0 col0\" >1398238</td>\n",
       "      <td id=\"T_5a18f_row0_col1\" class=\"data row0 col1\" >0.802</td>\n",
       "      <td id=\"T_5a18f_row0_col2\" class=\"data row0 col2\" >0.729</td>\n",
       "      <td id=\"T_5a18f_row0_col3\" class=\"data row0 col3\" >0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row1\" class=\"row_heading level0 row1\" >15</th>\n",
       "      <td id=\"T_5a18f_row1_col0\" class=\"data row1 col0\" >1072640</td>\n",
       "      <td id=\"T_5a18f_row1_col1\" class=\"data row1 col1\" >0.803</td>\n",
       "      <td id=\"T_5a18f_row1_col2\" class=\"data row1 col2\" >0.730</td>\n",
       "      <td id=\"T_5a18f_row1_col3\" class=\"data row1 col3\" >0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row2\" class=\"row_heading level0 row2\" >9</th>\n",
       "      <td id=\"T_5a18f_row2_col0\" class=\"data row2 col0\" >1732870</td>\n",
       "      <td id=\"T_5a18f_row2_col1\" class=\"data row2 col1\" >0.808</td>\n",
       "      <td id=\"T_5a18f_row2_col2\" class=\"data row2 col2\" >0.736</td>\n",
       "      <td id=\"T_5a18f_row2_col3\" class=\"data row2 col3\" >0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_5a18f_row3_col0\" class=\"data row3 col0\" >1535488</td>\n",
       "      <td id=\"T_5a18f_row3_col1\" class=\"data row3 col1\" >0.813</td>\n",
       "      <td id=\"T_5a18f_row3_col2\" class=\"data row3 col2\" >0.742</td>\n",
       "      <td id=\"T_5a18f_row3_col3\" class=\"data row3 col3\" >0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row4\" class=\"row_heading level0 row4\" >22</th>\n",
       "      <td id=\"T_5a18f_row4_col0\" class=\"data row4 col0\" >1964551</td>\n",
       "      <td id=\"T_5a18f_row4_col1\" class=\"data row4 col1\" >0.813</td>\n",
       "      <td id=\"T_5a18f_row4_col2\" class=\"data row4 col2\" >0.743</td>\n",
       "      <td id=\"T_5a18f_row4_col3\" class=\"data row4 col3\" >0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row5\" class=\"row_heading level0 row5\" >37</th>\n",
       "      <td id=\"T_5a18f_row5_col0\" class=\"data row5 col0\" >1953266</td>\n",
       "      <td id=\"T_5a18f_row5_col1\" class=\"data row5 col1\" >0.826</td>\n",
       "      <td id=\"T_5a18f_row5_col2\" class=\"data row5 col2\" >0.759</td>\n",
       "      <td id=\"T_5a18f_row5_col3\" class=\"data row5 col3\" >0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row6\" class=\"row_heading level0 row6\" >12</th>\n",
       "      <td id=\"T_5a18f_row6_col0\" class=\"data row6 col0\" >1870948</td>\n",
       "      <td id=\"T_5a18f_row6_col1\" class=\"data row6 col1\" >0.828</td>\n",
       "      <td id=\"T_5a18f_row6_col2\" class=\"data row6 col2\" >0.761</td>\n",
       "      <td id=\"T_5a18f_row6_col3\" class=\"data row6 col3\" >0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row7\" class=\"row_heading level0 row7\" >23</th>\n",
       "      <td id=\"T_5a18f_row7_col0\" class=\"data row7 col0\" >1121796</td>\n",
       "      <td id=\"T_5a18f_row7_col1\" class=\"data row7 col1\" >0.831</td>\n",
       "      <td id=\"T_5a18f_row7_col2\" class=\"data row7 col2\" >0.765</td>\n",
       "      <td id=\"T_5a18f_row7_col3\" class=\"data row7 col3\" >0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row8\" class=\"row_heading level0 row8\" >25</th>\n",
       "      <td id=\"T_5a18f_row8_col0\" class=\"data row8 col0\" >1275576</td>\n",
       "      <td id=\"T_5a18f_row8_col1\" class=\"data row8 col1\" >0.831</td>\n",
       "      <td id=\"T_5a18f_row8_col2\" class=\"data row8 col2\" >0.765</td>\n",
       "      <td id=\"T_5a18f_row8_col3\" class=\"data row8 col3\" >0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row9\" class=\"row_heading level0 row9\" >28</th>\n",
       "      <td id=\"T_5a18f_row9_col0\" class=\"data row9 col0\" >1920391</td>\n",
       "      <td id=\"T_5a18f_row9_col1\" class=\"data row9 col1\" >0.835</td>\n",
       "      <td id=\"T_5a18f_row9_col2\" class=\"data row9 col2\" >0.771</td>\n",
       "      <td id=\"T_5a18f_row9_col3\" class=\"data row9 col3\" >0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row10\" class=\"row_heading level0 row10\" >2</th>\n",
       "      <td id=\"T_5a18f_row10_col0\" class=\"data row10 col0\" >1334216</td>\n",
       "      <td id=\"T_5a18f_row10_col1\" class=\"data row10 col1\" >0.836</td>\n",
       "      <td id=\"T_5a18f_row10_col2\" class=\"data row10 col2\" >0.772</td>\n",
       "      <td id=\"T_5a18f_row10_col3\" class=\"data row10 col3\" >0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row11\" class=\"row_heading level0 row11\" >21</th>\n",
       "      <td id=\"T_5a18f_row11_col0\" class=\"data row11 col0\" >1954677</td>\n",
       "      <td id=\"T_5a18f_row11_col1\" class=\"data row11 col1\" >0.836</td>\n",
       "      <td id=\"T_5a18f_row11_col2\" class=\"data row11 col2\" >0.772</td>\n",
       "      <td id=\"T_5a18f_row11_col3\" class=\"data row11 col3\" >0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row12\" class=\"row_heading level0 row12\" >24</th>\n",
       "      <td id=\"T_5a18f_row12_col0\" class=\"data row12 col0\" >1244272</td>\n",
       "      <td id=\"T_5a18f_row12_col1\" class=\"data row12 col1\" >0.838</td>\n",
       "      <td id=\"T_5a18f_row12_col2\" class=\"data row12 col2\" >0.775</td>\n",
       "      <td id=\"T_5a18f_row12_col3\" class=\"data row12 col3\" >0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row13\" class=\"row_heading level0 row13\" >35</th>\n",
       "      <td id=\"T_5a18f_row13_col0\" class=\"data row13 col0\" >1781601</td>\n",
       "      <td id=\"T_5a18f_row13_col1\" class=\"data row13 col1\" >0.843</td>\n",
       "      <td id=\"T_5a18f_row13_col2\" class=\"data row13 col2\" >0.781</td>\n",
       "      <td id=\"T_5a18f_row13_col3\" class=\"data row13 col3\" >0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row14\" class=\"row_heading level0 row14\" >16</th>\n",
       "      <td id=\"T_5a18f_row14_col0\" class=\"data row14 col0\" >1125402</td>\n",
       "      <td id=\"T_5a18f_row14_col1\" class=\"data row14 col1\" >0.850</td>\n",
       "      <td id=\"T_5a18f_row14_col2\" class=\"data row14 col2\" >0.790</td>\n",
       "      <td id=\"T_5a18f_row14_col3\" class=\"data row14 col3\" >0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row15\" class=\"row_heading level0 row15\" >1</th>\n",
       "      <td id=\"T_5a18f_row15_col0\" class=\"data row15 col0\" >1318046</td>\n",
       "      <td id=\"T_5a18f_row15_col1\" class=\"data row15 col1\" >0.852</td>\n",
       "      <td id=\"T_5a18f_row15_col2\" class=\"data row15 col2\" >0.792</td>\n",
       "      <td id=\"T_5a18f_row15_col3\" class=\"data row15 col3\" >0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_5a18f_row16_col0\" class=\"data row16 col0\" >1323750</td>\n",
       "      <td id=\"T_5a18f_row16_col1\" class=\"data row16 col1\" >0.853</td>\n",
       "      <td id=\"T_5a18f_row16_col2\" class=\"data row16 col2\" >0.794</td>\n",
       "      <td id=\"T_5a18f_row16_col3\" class=\"data row16 col3\" >0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row17\" class=\"row_heading level0 row17\" >20</th>\n",
       "      <td id=\"T_5a18f_row17_col0\" class=\"data row17 col0\" >1859767</td>\n",
       "      <td id=\"T_5a18f_row17_col1\" class=\"data row17 col1\" >0.854</td>\n",
       "      <td id=\"T_5a18f_row17_col2\" class=\"data row17 col2\" >0.795</td>\n",
       "      <td id=\"T_5a18f_row17_col3\" class=\"data row17 col3\" >0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row18\" class=\"row_heading level0 row18\" >5</th>\n",
       "      <td id=\"T_5a18f_row18_col0\" class=\"data row18 col0\" >1544562</td>\n",
       "      <td id=\"T_5a18f_row18_col1\" class=\"data row18 col1\" >0.857</td>\n",
       "      <td id=\"T_5a18f_row18_col2\" class=\"data row18 col2\" >0.800</td>\n",
       "      <td id=\"T_5a18f_row18_col3\" class=\"data row18 col3\" >0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row19\" class=\"row_heading level0 row19\" >18</th>\n",
       "      <td id=\"T_5a18f_row19_col0\" class=\"data row19 col0\" >1356373</td>\n",
       "      <td id=\"T_5a18f_row19_col1\" class=\"data row19 col1\" >0.859</td>\n",
       "      <td id=\"T_5a18f_row19_col2\" class=\"data row19 col2\" >0.801</td>\n",
       "      <td id=\"T_5a18f_row19_col3\" class=\"data row19 col3\" >0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row20\" class=\"row_heading level0 row20\" >36</th>\n",
       "      <td id=\"T_5a18f_row20_col0\" class=\"data row20 col0\" >1887001</td>\n",
       "      <td id=\"T_5a18f_row20_col1\" class=\"data row20 col1\" >0.861</td>\n",
       "      <td id=\"T_5a18f_row20_col2\" class=\"data row20 col2\" >0.804</td>\n",
       "      <td id=\"T_5a18f_row20_col3\" class=\"data row20 col3\" >0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row21\" class=\"row_heading level0 row21\" >34</th>\n",
       "      <td id=\"T_5a18f_row21_col0\" class=\"data row21 col0\" >1649859</td>\n",
       "      <td id=\"T_5a18f_row21_col1\" class=\"data row21 col1\" >0.861</td>\n",
       "      <td id=\"T_5a18f_row21_col2\" class=\"data row21 col2\" >0.804</td>\n",
       "      <td id=\"T_5a18f_row21_col3\" class=\"data row21 col3\" >0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row22\" class=\"row_heading level0 row22\" >30</th>\n",
       "      <td id=\"T_5a18f_row22_col0\" class=\"data row22 col0\" >1107733</td>\n",
       "      <td id=\"T_5a18f_row22_col1\" class=\"data row22 col1\" >0.874</td>\n",
       "      <td id=\"T_5a18f_row22_col2\" class=\"data row22 col2\" >0.821</td>\n",
       "      <td id=\"T_5a18f_row22_col3\" class=\"data row22 col3\" >0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row23\" class=\"row_heading level0 row23\" >14</th>\n",
       "      <td id=\"T_5a18f_row23_col0\" class=\"data row23 col0\" >1030369</td>\n",
       "      <td id=\"T_5a18f_row23_col1\" class=\"data row23 col1\" >0.880</td>\n",
       "      <td id=\"T_5a18f_row23_col2\" class=\"data row23 col2\" >0.830</td>\n",
       "      <td id=\"T_5a18f_row23_col3\" class=\"data row23 col3\" >0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row24\" class=\"row_heading level0 row24\" >0</th>\n",
       "      <td id=\"T_5a18f_row24_col0\" class=\"data row24 col0\" >1304244</td>\n",
       "      <td id=\"T_5a18f_row24_col1\" class=\"data row24 col1\" >0.885</td>\n",
       "      <td id=\"T_5a18f_row24_col2\" class=\"data row24 col2\" >0.837</td>\n",
       "      <td id=\"T_5a18f_row24_col3\" class=\"data row24 col3\" >0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row25\" class=\"row_heading level0 row25\" >11</th>\n",
       "      <td id=\"T_5a18f_row25_col0\" class=\"data row25 col0\" >1840717</td>\n",
       "      <td id=\"T_5a18f_row25_col1\" class=\"data row25 col1\" >0.886</td>\n",
       "      <td id=\"T_5a18f_row25_col2\" class=\"data row25 col2\" >0.838</td>\n",
       "      <td id=\"T_5a18f_row25_col3\" class=\"data row25 col3\" >0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row26\" class=\"row_heading level0 row26\" >27</th>\n",
       "      <td id=\"T_5a18f_row26_col0\" class=\"data row26 col0\" >1576041</td>\n",
       "      <td id=\"T_5a18f_row26_col1\" class=\"data row26 col1\" >0.887</td>\n",
       "      <td id=\"T_5a18f_row26_col2\" class=\"data row26 col2\" >0.839</td>\n",
       "      <td id=\"T_5a18f_row26_col3\" class=\"data row26 col3\" >0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row27\" class=\"row_heading level0 row27\" >7</th>\n",
       "      <td id=\"T_5a18f_row27_col0\" class=\"data row27 col0\" >1638896</td>\n",
       "      <td id=\"T_5a18f_row27_col1\" class=\"data row27 col1\" >0.890</td>\n",
       "      <td id=\"T_5a18f_row27_col2\" class=\"data row27 col2\" >0.844</td>\n",
       "      <td id=\"T_5a18f_row27_col3\" class=\"data row27 col3\" >0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row28\" class=\"row_heading level0 row28\" >19</th>\n",
       "      <td id=\"T_5a18f_row28_col0\" class=\"data row28 col0\" >1600492</td>\n",
       "      <td id=\"T_5a18f_row28_col1\" class=\"data row28 col1\" >0.910</td>\n",
       "      <td id=\"T_5a18f_row28_col2\" class=\"data row28 col2\" >0.870</td>\n",
       "      <td id=\"T_5a18f_row28_col3\" class=\"data row28 col3\" >0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row29\" class=\"row_heading level0 row29\" >3</th>\n",
       "      <td id=\"T_5a18f_row29_col0\" class=\"data row29 col0\" >1512450</td>\n",
       "      <td id=\"T_5a18f_row29_col1\" class=\"data row29 col1\" >0.921</td>\n",
       "      <td id=\"T_5a18f_row29_col2\" class=\"data row29 col2\" >0.886</td>\n",
       "      <td id=\"T_5a18f_row29_col3\" class=\"data row29 col3\" >0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row30\" class=\"row_heading level0 row30\" >8</th>\n",
       "      <td id=\"T_5a18f_row30_col0\" class=\"data row30 col0\" >1730425</td>\n",
       "      <td id=\"T_5a18f_row30_col1\" class=\"data row30 col1\" >0.923</td>\n",
       "      <td id=\"T_5a18f_row30_col2\" class=\"data row30 col2\" >0.888</td>\n",
       "      <td id=\"T_5a18f_row30_col3\" class=\"data row30 col3\" >0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row31\" class=\"row_heading level0 row31\" >33</th>\n",
       "      <td id=\"T_5a18f_row31_col0\" class=\"data row31 col0\" >1120634</td>\n",
       "      <td id=\"T_5a18f_row31_col1\" class=\"data row31 col1\" >0.924</td>\n",
       "      <td id=\"T_5a18f_row31_col2\" class=\"data row31 col2\" >0.890</td>\n",
       "      <td id=\"T_5a18f_row31_col3\" class=\"data row31 col3\" >0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row32\" class=\"row_heading level0 row32\" >10</th>\n",
       "      <td id=\"T_5a18f_row32_col0\" class=\"data row32 col0\" >1748906</td>\n",
       "      <td id=\"T_5a18f_row32_col1\" class=\"data row32 col1\" >0.929</td>\n",
       "      <td id=\"T_5a18f_row32_col2\" class=\"data row32 col2\" >0.897</td>\n",
       "      <td id=\"T_5a18f_row32_col3\" class=\"data row32 col3\" >0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row33\" class=\"row_heading level0 row33\" >32</th>\n",
       "      <td id=\"T_5a18f_row33_col0\" class=\"data row33 col0\" >1117871</td>\n",
       "      <td id=\"T_5a18f_row33_col1\" class=\"data row33 col1\" >0.937</td>\n",
       "      <td id=\"T_5a18f_row33_col2\" class=\"data row33 col2\" >0.908</td>\n",
       "      <td id=\"T_5a18f_row33_col3\" class=\"data row33 col3\" >0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row34\" class=\"row_heading level0 row34\" >29</th>\n",
       "      <td id=\"T_5a18f_row34_col0\" class=\"data row34 col0\" >1988412</td>\n",
       "      <td id=\"T_5a18f_row34_col1\" class=\"data row34 col1\" >0.947</td>\n",
       "      <td id=\"T_5a18f_row34_col2\" class=\"data row34 col2\" >0.923</td>\n",
       "      <td id=\"T_5a18f_row34_col3\" class=\"data row34 col3\" >0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row35\" class=\"row_heading level0 row35\" >31</th>\n",
       "      <td id=\"T_5a18f_row35_col0\" class=\"data row35 col0\" >1116029</td>\n",
       "      <td id=\"T_5a18f_row35_col1\" class=\"data row35 col1\" >0.962</td>\n",
       "      <td id=\"T_5a18f_row35_col2\" class=\"data row35 col2\" >0.944</td>\n",
       "      <td id=\"T_5a18f_row35_col3\" class=\"data row35 col3\" >0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row36\" class=\"row_heading level0 row36\" >13</th>\n",
       "      <td id=\"T_5a18f_row36_col0\" class=\"data row36 col0\" >1884384</td>\n",
       "      <td id=\"T_5a18f_row36_col1\" class=\"data row36 col1\" >0.974</td>\n",
       "      <td id=\"T_5a18f_row36_col2\" class=\"data row36 col2\" >0.961</td>\n",
       "      <td id=\"T_5a18f_row36_col3\" class=\"data row36 col3\" >0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a18f_level0_row37\" class=\"row_heading level0 row37\" >6</th>\n",
       "      <td id=\"T_5a18f_row37_col0\" class=\"data row37 col0\" >1561239</td>\n",
       "      <td id=\"T_5a18f_row37_col1\" class=\"data row37 col1\" >0.995</td>\n",
       "      <td id=\"T_5a18f_row37_col2\" class=\"data row37 col2\" >0.992</td>\n",
       "      <td id=\"T_5a18f_row37_col3\" class=\"data row37 col3\" >0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x122ae34d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/16 04:33:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:33:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:33:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:34:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:50:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:50:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:50:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:50:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 04:50:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:08:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:08:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:08:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:08:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:08:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:25:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:25:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:26:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:26:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:26:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:26:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:41:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:42:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:42:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:42:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:42:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:58:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:58:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:59:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:59:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 05:59:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:14:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:14:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:14:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:14:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:14:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:30:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:30:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:30:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:30:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:31:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:47:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:48:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:48:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 06:48:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:03:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:03:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:03:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:04:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:04:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:04:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:19:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:19:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
      "\t... 17 more\n",
      "25/10/16 07:19:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:20:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:20:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:20:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:20:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:37:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:37:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:38:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.55:55856\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/10/16 07:38:01 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "high_risk_users = pdf[pdf[\"prob_churn\"] > 0.8].copy() # threshold is 0.8\n",
    "high_risk_users[\"original_prob\"] = high_risk_users[\"prob_churn\"]\n",
    "\n",
    "high_risk_users[\"active_days\"] += 5\n",
    "\n",
    "X_sim = high_risk_users[[\"userId\"] + feature_cols]\n",
    "\n",
    "X_sim_spark = spark.createDataFrame(X_sim)\n",
    "simulated_preds = lr_model.transform(X_sim_spark).select(\"userId\", \"probability\").toPandas()\n",
    "\n",
    "simulated_preds[\"new_prob\"] = simulated_preds[\"probability\"].apply(lambda x: float(x[1]))\n",
    "simulated_preds = simulated_preds[[\"userId\", \"new_prob\"]]\n",
    "\n",
    "high_risk_users = high_risk_users.merge(simulated_preds, on=\"userId\", how=\"left\")\n",
    "high_risk_users[\"probability_drop\"] = high_risk_users[\"original_prob\"] - high_risk_users[\"new_prob\"]\n",
    "\n",
    "cols_to_fix = [\"original_prob\", \"new_prob\", \"probability_drop\"]\n",
    "for col in cols_to_fix:\n",
    "    high_risk_users[col] = pd.to_numeric(high_risk_users[col], errors=\"coerce\")\n",
    "\n",
    "result = high_risk_users.dropna(subset=cols_to_fix)[[\"userId\"] + cols_to_fix]\n",
    "result = high_risk_users.dropna(subset=cols_to_fix)[[\"userId\", \"original_prob\", \"new_prob\", \"probability_drop\"]] \\\n",
    "         .sort_values(\"probability_drop\", ascending=False)\n",
    "\n",
    "display(\n",
    "    result.style\n",
    "    .format({col: \"{:.3f}\" for col in cols_to_fix})\n",
    "    .background_gradient(cmap=\"RdYlGn_r\", subset=[\"probability_drop\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cb6cc",
   "metadata": {},
   "source": [
    "As we can see, model responds strongly to active_days. A simple increase of five active days led to a churn probability drop of 5–7 percentage points for many high-risk users. Even users with an original churn risk above 0.85 became less likely to leave.\n",
    "\n",
    "This suggests that consistent activity is a powerful retention signal. More importantly, it shows that high-risk users aren’t a lost cause — they’re still responsive. A small behavioral shift can make a measurable difference.\n",
    "\n",
    "From a business standpoint, this supports low-cost interventions like nudges, re-engagement emails, or personalized content. The model doesn’t just predict churn — it points to actions that can help prevent it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a2095",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "In this notebook, I built a baseline churn prediction model using logistic regression. The model was trained on user engagement features and achieved a solid ROC-AUC of ~0.855, indicating strong separability between churned and retained users.\n",
    "\n",
    "Beyond classification, I explored actionable simulations by increasing active_days for high-risk users, demonstrating that engagement can significantly reduce churn probability for certain segments. This analysis helps translate model insights into practical retention strategies.\n",
    "\n",
    "**Why I Used Logistic Regression First?**\n",
    "\n",
    "* Speed & Simplicity: It trains quickly and is easy to interpret, making it ideal for initial modeling stages.\n",
    "* Probabilistic Output: Instead of just classifying churn/no churn, it provides churn risk scores, which are valuable for ranking users and targeting interventions.\n",
    "* Baseline Performance: It sets a clear, explainable baseline—helping us measure how much lift we gain from more advanced models later.\n",
    "* Low Overfitting Risk: On small to mid-sized datasets (like my dataset with ~20,000 users), it typically performs reliably without overfitting.\n",
    "\n",
    "But while logistic regression is a strong starting point, **it comes with important constraints:**\n",
    "\n",
    "* It creates linear decision boundaries, which means it may miss complex, nonlinear relationships between features.\n",
    "* It assumes feature independence, which isn’t always true in behavioral data like user activity logs.\n",
    "* It doesn’t capture interactions between features unless you manually engineer them.\n",
    "* And while it offers coefficients for interpretation, it lacks richer tools like tree-based feature importance or SHAP values for deeper explainability.\n",
    "\n",
    "These trade-offs are why more powerful models will be explored in the next stages.\n",
    "\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "With a strong baseline established, the next phase will focus on building more flexible and powerful models to improve prediction and uncover deeper behavioral patterns.Here’s what I’ll do next:\n",
    "\n",
    "* Test advanced classifiers like XGBoost, Random Forest, and Regularized Logistic Regression.\n",
    "* Compare model performance using metrics like AUC and precision-recall.\n",
    "* Analyze feature importance and explainability with SHAP values.\n",
    "* Simulate user behavior changes to see how predictions respond.\n",
    "* Evaluate robustness to noise and missing data.\n",
    "\n",
    "The goal is to move beyond prediction into understanding — and designing smarter, data-driven retention strategies. Please find my next notebook: [04_Random_Forest_&_XGBoost.ipynb](04_Random_Forest_&_XGBoost.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
